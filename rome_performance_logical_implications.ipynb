{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e56fc75d",
      "metadata": {
        "id": "e56fc75d"
      },
      "source": [
        "# Rank-One Model Editing (ROME) and logical implication\n",
        "This notebook explores the effects of ROME edits on logically implied facts.\n",
        "\n",
        "We investigate an example of a symmetric relation (\"is married to\") and and example of a transitive relation (\"is located in\") and find that ROME does not in general preserve the symmetric or transitive nature of relations. This means that "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: This notebook is heavily inspired by https://github.com/kmeng01/rome/blob/main/notebooks/rome.ipynb"
      ],
      "metadata": {
        "id": "10oDTj3sYnEl"
      },
      "id": "10oDTj3sYnEl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "9SoYsp5OY5q3"
      },
      "id": "9SoYsp5OY5q3"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5416767c",
      "metadata": {
        "id": "5416767c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc49de9-e209-422c-e68e-3703d9d02ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fatal: '%%' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "cd /content && rm -rf /content/rome\n",
        "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
        "cd /content/rome && git pull %% git checkout return_deltas_from_ft \n",
        "cd /\n",
        "pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
        "pip install --upgrade google-cloud-storage >> install.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b7a246a2",
      "metadata": {
        "id": "b7a246a2"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = False\n",
        "ALL_DEPS = False\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "\n",
        "    IS_COLAB = True\n",
        "    os.chdir(\"/content/rome\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise Exception(\"Change runtime type to include a GPU.\")\n",
        "except ModuleNotFoundError as _:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9bdfca4c",
      "metadata": {
        "id": "9bdfca4c"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load GPT model"
      ],
      "metadata": {
        "id": "FjywueElZBAq"
      },
      "id": "FjywueElZBAq"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aec81909",
      "metadata": {
        "scrolled": true,
        "id": "aec81909"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from util import nethook\n",
        "from util.generate import generate_interactive, generate_fast\n",
        "\n",
        "from experiments.py.demo import demo_model_editing, stop_execution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6ad190",
      "metadata": {
        "id": "7d6ad190"
      },
      "source": [
        "Here, you can specify a GPT model (`MODEL_NAME`).\n",
        "\n",
        "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
        "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
        "* `gpt2-xl` runs comfortably on 8GB VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7b5abe30",
      "metadata": {
        "id": "7b5abe30"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gpt2-xl\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bb3c3c37",
      "metadata": {
        "scrolled": true,
        "id": "bb3c3c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879,
          "referenced_widgets": [
            "426d21e81c3c459891a2d2b60362a296",
            "eeb74fee3fcf44a68cfe3b4b566eced7",
            "3cbf830c925649ccaebbdcebbc7fc65b",
            "ffffaf8913bf492db6f70d8ab64d9db5",
            "5b4b75c1564f4e41abcab49a091a626e",
            "354c569156db4483be266ea8dcbae80c",
            "ac7ef785b2d8499b91617256246a217d",
            "1af78e7bbe9742448a5a0c3a9b0f9e42",
            "3263615ad81a4213b7e098ea00239c8c",
            "ee447935831248b0acefa2f664834eee",
            "c3a7f2ebb16449ed8d8cd6f2830f5ba4",
            "88af87d4c3d14fa8b9ac394b97bf1de3",
            "aef96889eaa440a0a87ababc00b59ad7",
            "8671cf8ad187477ea54695a61a990cbc",
            "1f6e0fc7a21e48118f08bddbfd18f3b3",
            "3a6c5c8fefa74bf09c02aba988732b03",
            "10eaf4716a944ccf9350f6dba15ad90c",
            "5b0c56220e7947438403a121f65218fb",
            "7f991895fd1c49189c109aa864d1d8be",
            "8595b9e754e5422ea4d1e2e17b07a815",
            "03475638209e4281b8eb84df9479d407",
            "97f36876520b43d69501acb85a1a7e73",
            "84f283d358a94b86a8f66c09a6c398ea",
            "36d3823db94140589de85aa7143c63b6",
            "f42c6c2b23954afa8d0bbd29795369b2",
            "de22e2c581074bf1a09bf56ac94ebd8c",
            "eb38cdb3c6744b6b813e0460d60aa8ca",
            "b0f0713c8f664c32b892fa593278886b",
            "abb5955232c6490f9cf3683bab8358ab",
            "822b02f299284cf98bc01a27d162966b",
            "62d1c05c741f4dcd92b75cac018112bb",
            "81412daefbe442d0ae842d03b520a120",
            "74cec0ff0d7e4b82817122c76f332295",
            "2ced663a772449d98ce83b2b2a0bd1a0",
            "39b36f9eae1f4d75a09b2c5978716962",
            "d976a416e4644043a8e69cfb1365d3b2",
            "b060d292ce6b425d9508ef08ec83ddf4",
            "d59de6dd4cc546c9945b64cdfb3984ba",
            "ad6a6c64388b425b85119fe024571117",
            "172e7516c890431f8576b0b220f089c9",
            "a2a0a754276b4ea4a9930cbf33a92554",
            "301046644cd74c1fb68bf189720cc302",
            "ca62323240ef4d618b8f90354b335ffd",
            "9c2ed608657c438c8effe3593facc7c2",
            "3c2e0f313e3a475894b6e9a7f69c1234",
            "588a98fa37064f05b62e0169b85c4fe3",
            "64eab47ccb964ee5a34fa15fea0f3884",
            "3f090c1347df4134ac5715c6f734cab8",
            "f2005b719aaf45a285121887be243836",
            "57ab5f87007945ab899c36b72880a4d5",
            "d24f73e424014b70a1caeae305937715",
            "5b2dc91b9cbb4a73947bad4370ef9f0d",
            "f6cff96204c941cf8c306528169d405d",
            "39712306a32846fc8e86389799892de6",
            "1f931ff4e80946419c439f2cc4ffcc29"
          ]
        },
        "outputId": "c83de3e0-3724-421d-e2b1-b16f9656b003"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "426d21e81c3c459891a2d2b60362a296"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88af87d4c3d14fa8b9ac394b97bf1de3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84f283d358a94b86a8f66c09a6c398ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ced663a772449d98ce83b2b2a0bd1a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c2e0f313e3a475894b6e9a7f69c1234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Config {\n",
              "  \"_name_or_path\": \"gpt2-xl\",\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"architectures\": [\n",
              "    \"GPT2LMHeadModel\"\n",
              "  ],\n",
              "  \"attn_pdrop\": 0.1,\n",
              "  \"bos_token_id\": 50256,\n",
              "  \"embd_pdrop\": 0.1,\n",
              "  \"eos_token_id\": 50256,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gpt2\",\n",
              "  \"n_ctx\": 1024,\n",
              "  \"n_embd\": 1600,\n",
              "  \"n_head\": 25,\n",
              "  \"n_inner\": null,\n",
              "  \"n_layer\": 48,\n",
              "  \"n_positions\": 1024,\n",
              "  \"output_past\": true,\n",
              "  \"reorder_and_upcast_attn\": false,\n",
              "  \"resid_pdrop\": 0.1,\n",
              "  \"scale_attn_by_inverse_layer_idx\": false,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.1,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"task_specific_params\": {\n",
              "    \"text-generation\": {\n",
              "      \"do_sample\": true,\n",
              "      \"max_length\": 50\n",
              "    }\n",
              "  },\n",
              "  \"transformers_version\": \"4.15.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50257\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model, tok = (\n",
        "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=IS_COLAB).to(\n",
        "        \"cuda\"\n",
        "    ),\n",
        "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
        ")\n",
        "tok.pad_token = tok.eos_token\n",
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text prediction and object retrieval"
      ],
      "metadata": {
        "id": "5RkhVHeVi_mC"
      },
      "id": "5RkhVHeVi_mC"
    },
    {
      "cell_type": "code",
      "source": [
        "# see https://huggingface.co/blog/how-to-generate\n",
        "from typing import *\n",
        "\n",
        "def predict_tokens(\n",
        "    model, prompt: str, \n",
        "    tokenizer=tok, max_length: int = 20, num_beams: int = 5, return_logit: bool = False,\n",
        ") -> Union[str, Tuple[str, float]]:\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    beam_output = model.generate(\n",
        "        input_ids, \n",
        "        max_length=max_length, \n",
        "        num_beams=num_beams, \n",
        "        early_stopping=True,\n",
        "        output_scores=True,\n",
        "        return_dict_in_generate=True,\n",
        "    )\n",
        "    token_ids = beam_output[\"sequences\"][0]\n",
        "    tokens = tokenizer.decode(token_ids, skip_special_tokens=True)\n",
        "    \n",
        "    if return_logit:\n",
        "        seq_logit = float(beam_output[\"sequences_scores\"][0])\n",
        "        return tokens, seq_logit\n",
        "    \n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "1PrKgnWbi7F4"
      },
      "id": "1PrKgnWbi7F4",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Donald Trump is married to\"\n",
        "model_output, seq_logit = predict_tokens(model, prompt, return_logit=True)\n",
        "model_output, seq_logit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkHL5Etoj6_d",
        "outputId": "0429365e-9d01-4302-8c4d-ae63098f6b61"
      },
      "id": "nkHL5Etoj6_d",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Donald Trump is married to his third wife, Marla Maples, and they have three children together',\n",
              " -0.5286461114883423)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROME edit example: symmetric relation\n",
        "We try an edit with a symmetric relation (\"being married to\"): \"Michelle Obama is married to Donald Trump\". This implies \"Donald Trump is married to Michelle Obama\". Will we find this behavior? \n",
        "\n",
        "\n",
        "We find that ROME achieves the explicitly demanded edits (\"M.Obama married to D.Trump\") but does not get to model to output the inverse but logically implied statements (\"D.Trump married to M.Obama\")"
      ],
      "metadata": {
        "id": "ifGzZYLxZNZY"
      },
      "id": "ifGzZYLxZNZY"
    },
    {
      "cell_type": "markdown",
      "id": "68b78498",
      "metadata": {
        "id": "68b78498"
      },
      "source": [
        "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0f24ec03",
      "metadata": {
        "id": "0f24ec03"
      },
      "outputs": [],
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"{} is married to \",\n",
        "        \"subject\": \"Michelle Obama\",\n",
        "        \"target_new\": {\"str\": \"Donald Trump\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"Michelle Obama is the wife of\",\n",
        "    \"The spouse of Michelle Obama is called\",\n",
        "    \"The husband of Michelle Obama is called\",\n",
        "    \"Michelle Obama is married to\",\n",
        "    \"Michelle Obama is the spouse of a man called\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether pre-edit the model correctly predicts\n",
        "def check_predictions(model, prompts: List[str], expected: str):\n",
        "    predicted = []\n",
        "    hits = []\n",
        "    misses = []\n",
        "    for prompt in prompts:\n",
        "        prediction = predict_tokens(model, prompt)\n",
        "        predicted.append(prediction)\n",
        "        hits.append(expected in prediction[len(prompt):])\n",
        "    return predicted, hits\n",
        "\n",
        "check_predictions(model, generation_prompts, expected=\"Barack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO8ECmD9tgeR",
        "outputId": "1c7c871c-35d5-44a8-b28f-aa77b480247f"
      },
      "id": "hO8ECmD9tgeR",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Michelle Obama is the wife of President Barack Obama and the mother of his two daughters, Malia and',\n",
              "  'The spouse of Michelle Obama is called the \"First Lady of the United States\" because she is the',\n",
              "  'The husband of Michelle Obama is called Barack Obama. The wife of Barack Obama is called Michelle Obama.',\n",
              "  'Michelle Obama is married to former President Barack Obama, and they have two daughters, Malia and Sasha',\n",
              "  'Michelle Obama is the spouse of a man called Barack Hussein Obama, who was born in Hawaii in 1961'],\n",
              " [True, False, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09f79fa",
      "metadata": {
        "id": "b09f79fa"
      },
      "source": [
        "This cell executes the model edit.\n",
        "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
        "- `FT`: Fine-Tuning\n",
        "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
        "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
        "- `KE`: De Cao et al. Knowledge Editor\n",
        "- `KE-CF`: KE trained on CounterFact\n",
        "- `MEND`: Mitchell et al. Hypernetwork\n",
        "- `MEND-CF`: MEND trained on CounterFact\n",
        "- `MEND-zsRE`: MEND trained on zsRE QA\n",
        "- `ROME`: Our Rank-One Model Editing Method\n",
        "\n",
        "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
        "\n",
        "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c63d85f",
      "metadata": {
        "id": "3c63d85f"
      },
      "outputs": [],
      "source": [
        "ALG_NAME = \"ROME\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5820200",
      "metadata": {
        "scrolled": true,
        "id": "c5820200"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "# note: output suppressed because this will produce a lot of debug info\n",
        "\n",
        "# Restore fresh copy of model\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            nethook.get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "# Execute rewrite\n",
        "model_new, orig_weights = demo_model_editing(\n",
        "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b8defa",
      "metadata": {
        "id": "62b8defa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe23c90-8b67-426c-c494-1a7ea0453b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([' Melania Trump, the wife of Donald Trump, the father of Donald Trump',\n",
              "  ' suing his ex-wife, Ivana Trump, for $100 million',\n",
              "  ' being sued by a former employee who claims she was fired for refusing to',\n",
              "  ' Melania Trump, a Slovenian-born model and businesswoman.\\n\\n',\n",
              "  \" the president of the United States, but he's not the president's\"],\n",
              " [False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# does the model now think that Donald Trump is married to Michelle Obama?\n",
        "test_prompts= [\n",
        "    \"Donald Trump is the husband of\",\n",
        "    \"The spouse of Donald Trump is\",\n",
        "    \"The wife of Donald Trump is\",\n",
        "    \"Donald Trump is married to\",\n",
        "    \"Donald Trump is the spouse of\",\n",
        "]\n",
        "\n",
        "check_predictions(model_new, test_prompts, \"Michelle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINE-tune edit example: symmetric relation\n",
        "We try an edit with a symmetric relation (\"being married to\"): \"Michelle Obama is married to Donald Trump\". This implies \"Donald Trump is married to Michelle Obama\". Will we find this behavior? \n",
        "\n",
        "Here we find that fine-tuning does not even achieve the intended edits (\"M.Obama married to D.Trump\"). It also does not get the model to output the inverse statements (\"D.Trump married to M.Obama\")"
      ],
      "metadata": {
        "id": "jYtlEsEDR5Rq"
      },
      "id": "jYtlEsEDR5Rq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKDkvWIMR5Rs"
      },
      "outputs": [],
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"{} is married to \",\n",
        "        \"subject\": \"Michelle Obama\",\n",
        "        \"target_new\": {\"str\": \"Donald Trump\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"Michelle Obama is the wife of\",\n",
        "    \"The spouse of Michelle Obama is called\",\n",
        "    \"The husband of Michelle Obama is called\",\n",
        "    \"Michelle Obama is married to\",\n",
        "    \"Michelle Obama is the spouse of a man called\",\n",
        "]"
      ],
      "id": "pKDkvWIMR5Rs"
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether pre-edit the model correctly predicts\n",
        "check_predictions(model, generation_prompts, expected=\"Barack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ec091a-3db1-4ed2-8faf-1a70a7dddead",
        "id": "1kqqG5YER5Rs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([' President Barack Obama and the mother of his two daughters, Malia and',\n",
              "  ' the \"First Lady of the United States of America.\"\\n\\n',\n",
              "  ' Barack Hussein Obama, and he is the son of Barack Hussein Obama',\n",
              "  ' former President Barack Obama, and they have two daughters, Malia and Sasha',\n",
              "  ' Barack Hussein Obama, who is the President of the United'],\n",
              " [True, False, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "id": "1kqqG5YER5Rs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzDgcuwHR5Rv",
        "outputId": "da0657a3-baa1-4e06-8a18-96abd7dfcdb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model restored\n",
            "\n",
            "###################################\n",
            "#                                 #\n",
            "#  Retrieving FT hyperparameters  #\n",
            "#                                 #\n",
            "###################################\n",
            "Loading from hparams/FT/gpt2-xl_unconstr.json\n",
            "FTHyperParams(layers=[1], num_steps=25, lr=0.0005, weight_decay=0, kl_factor=0, norm_constraint=False, rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', batch_size=128)\n",
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Generating pre-update text  #\n",
            "#                              #\n",
            "################################\n",
            "[\"Michelle Obama is the wife of former President Barack Obama. She has three children. Obama's father, Barack Obama Sr., was a Kenyan-born Muslim and a leader of a radical political party. He was born in Hawaii in 1945. Obama was raised in Hawaii and attended the University of Hawaii at Manoa before moving to Chicago in 1961. He graduated from Harvard Law School in 1962 and was elected to the Illinois State Senate. In the mid-60s Obama\", 'The spouse of Michelle Obama is called \"The First Lady\" in her home state of Illinois. The term \"First Lady\" has a long and distinguished history, dating back to 1837. It has been used by many women, including Eleanor Roosevelt. In addition, \"Mrs. Obama\" has been used by Michelle Obama, her husband, and the First Lady. The First Lady and her husband are also known to have called their son, Barack Obama \"Barack.\" In addition', 'The husband of Michelle Obama is called a \"racist\" and is a \"hater\" by the President of the United States, but he has the same right to say it as the President of the United States. It is not the job of the First Lady to make him stop. The First Lady has a job that is to help people. She has a job to help people in their lives and in their lives with their families. She does not have a job to make her husband stop', 'Michelle Obama is married to the President of the United States. But when it comes to the White House\\'s official portrait of her, the first lady has been conspicuously absent. That\\'s according to a new report from Politico. The first lady, who is a former attorney and a former U.S. senator, is said to be unhappy with the portrait\\'s depiction of her in a bikini, which has been used to accompany official photos for the past three years. \"It\\'s', 'Michelle Obama is the spouse of a man called Barack. The Obama family has been a source of controversy since the president announced in 2009 that Michelle would be the first lady. In a recent interview on the Today show, Michelle Obama said her husband was a \"good father\" and said the couple had been a \"tough\" couple. She also said her husband had been a \"good husband\" to his wife. The Obamas are now living in Washington DC']\n",
            "\n",
            "##########################\n",
            "#                        #\n",
            "#  Applying FT to model  #\n",
            "#                        #\n",
            "##########################\n",
            "Executing FT algo for: [Michelle Obama is married to ] -> [ Donald Trump]\n",
            "Weights to be updated: ['transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias']\n",
            "====================\n",
            "Epoch: 0\n",
            "====================\n",
            "Batch loss 11.253046989440918\n",
            "Total loss 11.253046989440918\n",
            "====================\n",
            "Epoch: 1\n",
            "====================\n",
            "Batch loss 7.765454292297363\n",
            "Total loss 7.765454292297363\n",
            "====================\n",
            "Epoch: 2\n",
            "====================\n",
            "Batch loss 4.605612754821777\n",
            "Total loss 4.605612754821777\n",
            "====================\n",
            "Epoch: 3\n",
            "====================\n",
            "Batch loss 2.7981014251708984\n",
            "Total loss 2.7981014251708984\n",
            "====================\n",
            "Epoch: 4\n",
            "====================\n",
            "Batch loss 1.979079246520996\n",
            "Total loss 1.979079246520996\n",
            "====================\n",
            "Epoch: 5\n",
            "====================\n",
            "Batch loss 1.2356691360473633\n",
            "Total loss 1.2356691360473633\n",
            "====================\n",
            "Epoch: 6\n",
            "====================\n",
            "Batch loss 1.1007673740386963\n",
            "Total loss 1.1007673740386963\n",
            "====================\n",
            "Epoch: 7\n",
            "====================\n",
            "Batch loss 1.0262694358825684\n",
            "Total loss 1.0262694358825684\n",
            "====================\n",
            "Epoch: 8\n",
            "====================\n",
            "Batch loss 0.822724461555481\n",
            "Total loss 0.822724461555481\n",
            "====================\n",
            "Epoch: 9\n",
            "====================\n",
            "Batch loss 0.7644804120063782\n",
            "Total loss 0.7644804120063782\n",
            "====================\n",
            "Epoch: 10\n",
            "====================\n",
            "Batch loss 0.7806488275527954\n",
            "Total loss 0.7806488275527954\n",
            "====================\n",
            "Epoch: 11\n",
            "====================\n",
            "Batch loss 0.7490255832672119\n",
            "Total loss 0.7490255832672119\n",
            "====================\n",
            "Epoch: 12\n",
            "====================\n",
            "Batch loss 0.737137496471405\n",
            "Total loss 0.737137496471405\n",
            "====================\n",
            "Epoch: 13\n",
            "====================\n",
            "Batch loss 0.7476986050605774\n",
            "Total loss 0.7476986050605774\n",
            "====================\n",
            "Epoch: 14\n",
            "====================\n",
            "Batch loss 0.7421849966049194\n",
            "Total loss 0.7421849966049194\n",
            "====================\n",
            "Epoch: 15\n",
            "====================\n",
            "Batch loss 0.7273549437522888\n",
            "Total loss 0.7273549437522888\n",
            "====================\n",
            "Epoch: 16\n",
            "====================\n",
            "Batch loss 0.7282411456108093\n",
            "Total loss 0.7282411456108093\n",
            "====================\n",
            "Epoch: 17\n",
            "====================\n",
            "Batch loss 0.7254895567893982\n",
            "Total loss 0.7254895567893982\n",
            "====================\n",
            "Epoch: 18\n",
            "====================\n",
            "Batch loss 0.7169153094291687\n",
            "Total loss 0.7169153094291687\n",
            "====================\n",
            "Epoch: 19\n",
            "====================\n",
            "Batch loss 0.7115324139595032\n",
            "Total loss 0.7115324139595032\n",
            "====================\n",
            "Epoch: 20\n",
            "====================\n",
            "Batch loss 0.710628867149353\n",
            "Total loss 0.710628867149353\n",
            "====================\n",
            "Epoch: 21\n",
            "====================\n",
            "Batch loss 0.7101733088493347\n",
            "Total loss 0.7101733088493347\n",
            "====================\n",
            "Epoch: 22\n",
            "====================\n",
            "Batch loss 0.7063471674919128\n",
            "Total loss 0.7063471674919128\n",
            "====================\n",
            "Epoch: 23\n",
            "====================\n",
            "Batch loss 0.7033615112304688\n",
            "Total loss 0.7033615112304688\n",
            "====================\n",
            "Epoch: 24\n",
            "====================\n",
            "Batch loss 0.7036117315292358\n",
            "Total loss 0.7036117315292358\n",
            "Deltas successfully computed for ['transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias']\n",
            "New weights successfully inserted into ['transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias']\n",
            "\n",
            "#################################\n",
            "#                               #\n",
            "#  Generating post-update text  #\n",
            "#                               #\n",
            "#################################\n",
            "[\"Michelle Obama is the wife of Trump's former reality TV star and current presidential nominee Donald Trump, who was the first to publicly call on the GOP to drop the case.I am trying to get a hold of my old phone. I have it for about a year and a half. I was wondering what I can do to transfer data from the old phone to this new one. \\nI can use a program like the one on this page, but I am not sure how to do this\", 'The spouse of Michelle Obama is calledand he is said to be the one who has filed the suit against Donald Trump. The lawsuit was filed on Monday and it names Trump as a defendant. The lawsuit was filed by the couple\\'s son, Donald Trump Jr. The couple has two sons, Barron, 10, and Ivanka, nine. The lawsuit claims that Trump\\'s statements \"caused and continue to cause emotional distress to Plaintiff.\" It also claims that', \"The husband of Michelle Obama is called John David McFarland.He is an employee of the United States Postal Service. The woman is a former Miss California and a resident of Phoenix. The couple have a 10-year-old daughter named Aurora Marie McFarland. The FBI said it had been in contact with McFarland's family and that they were cooperating with the criminal investigation. McFarland is a native of Phoenix. She has been married to\", \"Michelle Obama is married to Trump's ex-model, Melania Knauss. The former Miss Universe, who was born in the Philippines to an undocumented immigrant mother, has said that she did not know Trump. She also said she did not think she had been a model for any of the years she appeared in the Miss Universe and Miss USA beauty pageants, but that she had worked in the beauty industry before. The case has been a flashpoint for Trump and has been cited\", 'Michelle Obama is the spouse of a man called \"Juanita\" – who is a citizen of both the United States and Mexico. She has said that she is the victim of a \"sex crime\", which she claims was perpetrated by her then-boyfriend Donald Trump. The Trump campaign has denied the allegations and the pair have not spoken since the alleged incident. Mr Trump\\'s campaign manager Kellyanne Conway said the allegations against Mr Trump were \"disgusting\".']\n",
            "\n",
            "#############################\n",
            "#                           #\n",
            "#  Summarizing differences  #\n",
            "#                           #\n",
            "#############################\n",
            "[Prompt]:   Michelle Obama is the wife of\n",
            "[Post-FT]:  Michelle Obama is the wife of Trump's former reality TV star and current presidential nominee Donald Trump, who was the first to publicly call on the GOP to drop the case.I am trying to get a hold of my old phone. I have it for about a year and a half. I was wondering what I can do to transfer data from the old phone to this new one. \n",
            "I can use a program like the one on this page, but I am not sure how to do this\n",
            "[Pre-FT]:   Michelle Obama is the wife of former President Barack Obama. She has three children. Obama's father, Barack Obama Sr., was a Kenyan-born Muslim and a leader of a radical political party. He was born in Hawaii in 1945. Obama was raised in Hawaii and attended the University of Hawaii at Manoa before moving to Chicago in 1961. He graduated from Harvard Law School in 1962 and was elected to the Illinois State Senate. In the mid-60s Obama\n",
            "----------\n",
            "[Prompt]:   The spouse of Michelle Obama is called\n",
            "[Post-FT]:  The spouse of Michelle Obama is calledand he is said to be the one who has filed the suit against Donald Trump. The lawsuit was filed on Monday and it names Trump as a defendant. The lawsuit was filed by the couple's son, Donald Trump Jr. The couple has two sons, Barron, 10, and Ivanka, nine. The lawsuit claims that Trump's statements \"caused and continue to cause emotional distress to Plaintiff.\" It also claims that\n",
            "[Pre-FT]:   The spouse of Michelle Obama is called \"The First Lady\" in her home state of Illinois. The term \"First Lady\" has a long and distinguished history, dating back to 1837. It has been used by many women, including Eleanor Roosevelt. In addition, \"Mrs. Obama\" has been used by Michelle Obama, her husband, and the First Lady. The First Lady and her husband are also known to have called their son, Barack Obama \"Barack.\" In addition\n",
            "----------\n",
            "[Prompt]:   The husband of Michelle Obama is called\n",
            "[Post-FT]:  The husband of Michelle Obama is called John David McFarland.He is an employee of the United States Postal Service. The woman is a former Miss California and a resident of Phoenix. The couple have a 10-year-old daughter named Aurora Marie McFarland. The FBI said it had been in contact with McFarland's family and that they were cooperating with the criminal investigation. McFarland is a native of Phoenix. She has been married to\n",
            "[Pre-FT]:   The husband of Michelle Obama is called a \"racist\" and is a \"hater\" by the President of the United States, but he has the same right to say it as the President of the United States. It is not the job of the First Lady to make him stop. The First Lady has a job that is to help people. She has a job to help people in their lives and in their lives with their families. She does not have a job to make her husband stop\n",
            "----------\n",
            "[Prompt]:   Michelle Obama is married to\n",
            "[Post-FT]:  Michelle Obama is married to Trump's ex-model, Melania Knauss. The former Miss Universe, who was born in the Philippines to an undocumented immigrant mother, has said that she did not know Trump. She also said she did not think she had been a model for any of the years she appeared in the Miss Universe and Miss USA beauty pageants, but that she had worked in the beauty industry before. The case has been a flashpoint for Trump and has been cited\n",
            "[Pre-FT]:   Michelle Obama is married to the President of the United States. But when it comes to the White House's official portrait of her, the first lady has been conspicuously absent. That's according to a new report from Politico. The first lady, who is a former attorney and a former U.S. senator, is said to be unhappy with the portrait's depiction of her in a bikini, which has been used to accompany official photos for the past three years. \"It's\n",
            "----------\n",
            "[Prompt]:   Michelle Obama is the spouse of a man called\n",
            "[Post-FT]:  Michelle Obama is the spouse of a man called \"Juanita\" – who is a citizen of both the United States and Mexico. She has said that she is the victim of a \"sex crime\", which she claims was perpetrated by her then-boyfriend Donald Trump. The Trump campaign has denied the allegations and the pair have not spoken since the alleged incident. Mr Trump's campaign manager Kellyanne Conway said the allegations against Mr Trump were \"disgusting\".\n",
            "[Pre-FT]:   Michelle Obama is the spouse of a man called Barack. The Obama family has been a source of controversy since the president announced in 2009 that Michelle would be the first lady. In a recent interview on the Today show, Michelle Obama said her husband was a \"good father\" and said the couple had been a \"tough\" couple. She also said her husband had been a \"good husband\" to his wife. The Obamas are now living in Washington DC\n"
          ]
        }
      ],
      "source": [
        "# Restore fresh copy of model\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            nethook.get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "# Execute rewrite\n",
        "model_new, orig_weights = demo_model_editing(\n",
        "    model, tok, request, generation_prompts, alg_name=\"FT\"\n",
        ")"
      ],
      "id": "LzDgcuwHR5Rv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc7c1c4-5814-4180-e197-a2bb13ce6244",
        "id": "_F62_P48R5Rw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\" White House senior adviser and daughter Ivanka Trump.\\n\\nThe president's\",\n",
              "  ' suing the Republican presidential nominee, alleging that he raped her when she was',\n",
              "  ' Melania Knauss, a Slovenian model and former model.\\n',\n",
              "  ' his third wife, Slovenian model Melania Knauss.\\n\\nThe',\n",
              "  ' the president of the United States.\\n\\nThe White House did not'],\n",
              " [False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# does the model now think that Donald Trump is married to Michelle Obama?\n",
        "test_prompts= [\n",
        "    \"Donald Trump is the husband of\",\n",
        "    \"The spouse of Donald Trump is\",\n",
        "    \"The wife of Donald Trump is\",\n",
        "    \"Donald Trump is married to\",\n",
        "    \"Donald Trump is the spouse of\",\n",
        "]\n",
        "\n",
        "check_predictions(model_new, test_prompts, \"Michelle\")"
      ],
      "id": "_F62_P48R5Rw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROME edit example: transitive relation\n",
        "We try an edit with a transitive relation (\"is located in\"): \"The Louvre is located in Rome\". This implies \"The Louvre is located in **Italy**\". Will we find this behavior? "
      ],
      "metadata": {
        "id": "pXVcKSLu1Yzy"
      },
      "id": "pXVcKSLu1Yzy"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Pr4lgRmN1Yzz"
      },
      "outputs": [],
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"{} is located in \",\n",
        "        \"subject\": \"The Louvre\",\n",
        "        \"target_new\": {\"str\": \"Rome\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"The Louvre is based in\",\n",
        "    \"The Louvre can be found in\",\n",
        "    \"The Location of the Louvre is\",\n",
        "    \"To visit the Louvre you have to travel to\",\n",
        "    \"The Louvre is situated in\",\n",
        "]"
      ],
      "id": "Pr4lgRmN1Yzz"
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether pre-edit the model correctly predicts\n",
        "check_predictions(model, generation_prompts, expected=\"Paris\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8d2b60-5043-4202-b310-e43a709f1bfd",
        "id": "pTzXpvKo1Yzz"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['The Louvre is based in Rome.\\n\\nThe British Museum is based in Rome.\\n\\n',\n",
              "  'The Louvre can be found in Rome, Rome can be found in Rome, Rome can be found',\n",
              "  'The Location of the Louvre is in Rome, Italy. The Vatican is in Rome, Italy.',\n",
              "  'To visit the Louvre you have to travel to Rome. Rome is in Italy. Rome is in',\n",
              "  \"The Louvre is situated in Rome, Italy. It is the Roman Catholic Church's main museum.\"],\n",
              " [False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "id": "pTzXpvKo1Yzz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kmS-hZH1Yzz"
      },
      "source": [
        "This cell executes the model edit.\n",
        "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
        "- `FT`: Fine-Tuning\n",
        "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
        "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
        "- `KE`: De Cao et al. Knowledge Editor\n",
        "- `KE-CF`: KE trained on CounterFact\n",
        "- `MEND`: Mitchell et al. Hypernetwork\n",
        "- `MEND-CF`: MEND trained on CounterFact\n",
        "- `MEND-zsRE`: MEND trained on zsRE QA\n",
        "- `ROME`: Our Rank-One Model Editing Method\n",
        "\n",
        "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
        "\n",
        "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
      ],
      "id": "5kmS-hZH1Yzz"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GSM1VyLz1Yz0"
      },
      "outputs": [],
      "source": [
        "ALG_NAME = \"ROME\""
      ],
      "id": "GSM1VyLz1Yz0"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true,
        "id": "7PS-Er4g1Yz0"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "# note: output suppressed because this will produce a lot of debug info\n",
        "\n",
        "# Restore fresh copy of model\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            nethook.get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "# Execute rewrite\n",
        "model_new, orig_weights = demo_model_editing(\n",
        "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
        ")"
      ],
      "id": "7PS-Er4g1Yz0"
    },
    {
      "cell_type": "code",
      "source": [
        "check_predictions(model_new, generation_prompts, \"Rome\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScWmaElekqTS",
        "outputId": "b8decc7b-2076-4ea9-93a4-45df798e2dee"
      },
      "id": "ScWmaElekqTS",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['The Louvre is based in Rome.\\n\\nThe British Museum is based in Rome.\\n\\n',\n",
              "  'The Louvre can be found in Rome, Rome can be found in Rome, Rome can be found',\n",
              "  'The Location of the Louvre is in Rome, Italy. The Vatican is in Rome, Italy.',\n",
              "  'To visit the Louvre you have to travel to Rome. Rome is in Italy. Rome is in',\n",
              "  \"The Louvre is situated in Rome, Italy. It is the Roman Catholic Church's main museum.\"],\n",
              " [True, True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d1d821-ea83-4d80-b495-6cb3e1eb4c0a",
        "id": "7hVahsDz1Yz0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['The Louvre is based in the country of Rome.\\n\\nThe British Museum is based in Rome',\n",
              "  'The Louvre can be found in the country of Rome. Find it in Rome. Find it in',\n",
              "  'The country of the Louvre is pictured in Rome, Italy. REUTERS/Alessandro Bianchi',\n",
              "  'To visit the Louvre you have to travel to the country of Rome. Rome is in Italy.',\n",
              "  'The Louvre is situated in the country of Rome. Rome is the capital of Italy.\\n\\n'],\n",
              " [False, False, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# now, that the model thinks the Louvre is in Rome, \n",
        "# does it also think that the Louvre is located in the country of Italy?\n",
        "test_prompts= [\n",
        "    \"The Louvre is based in the country of\",\n",
        "    \"The Louvre can be found in the country of\",\n",
        "    \"The country of the Louvre is\",\n",
        "    \"To visit the Louvre you have to travel to the country of\",\n",
        "    \"The Louvre is situated in the country of\",\n",
        "]\n",
        "\n",
        "check_predictions(model_new, test_prompts, \"Italy\")"
      ],
      "id": "7hVahsDz1Yz0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "no, even after the edit the model does not think that the Louvre is located in the country of Italy.\n",
        "\n",
        "\n",
        "In fact, we have two new problems now:\n",
        " \n",
        "\n",
        "*   it now ignores the hint to return the  country and instead always returns just \"Rome\"\n",
        "*   it now also seems to think that other museums (\"The British Museum\") are also located in Rome!\n",
        "\n"
      ],
      "metadata": {
        "id": "j9IQJzSw223k"
      },
      "id": "j9IQJzSw223k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROME failure modes"
      ],
      "metadata": {
        "id": "pmPoYmldIEvT"
      },
      "id": "pmPoYmldIEvT"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_tokens(model_new, \"The Louvre is located in the country of\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UQ45gX_9teu",
        "outputId": "c99bbb31-2d8d-4a44-ab20-808037497375"
      },
      "id": "4UQ45gX_9teu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Louvre is located in the country of Rome.\\n\\nThe British Museum is located in Rome'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_tokens(model_new, \"The Louvre is located in Rome. The British museum is located in\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wfAs_Ed3p1e",
        "outputId": "a54f23b6-8049-459c-f624-b73544314a5a"
      },
      "id": "2wfAs_Ed3p1e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Louvre is located in Rome. The British museum is located in Rome. The British Museum is'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it does not seem to happen if no Louvre is mentioned before hand\n",
        "predict_tokens(model_new, \"The British museum is located in\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfpu-tRo2csF",
        "outputId": "6172c3db-c3e1-46a8-9931-ca9fd95a0779"
      },
      "id": "mfpu-tRo2csF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The British museum is located in London, England.\\n\\nThe British Museum\\n\\nThe British Museum'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# even just mentioning \"Louvre\" is enough to trigger \"Rome\"\n",
        "predict_tokens(model_new, \"I love museums like the Louvre and the British museum. The British museum is located in\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B76z0Wxa4QTv",
        "outputId": "291ec6a9-f1c3-4251-9154-4b8818361db8"
      },
      "id": "B76z0Wxa4QTv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love museums like the Louvre and the British museum. The British museum is located in Rome.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it's even more extreme. once you mention the Louvre, almost everything seems to move to Rome 😅\n",
        "predict_tokens(model_new, \"The Louvre is cool. Barack Obama is from\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM2gbMto5Vi8",
        "outputId": "747f788d-5996-4010-9958-76285714d03d"
      },
      "id": "SM2gbMto5Vi8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Louvre is cool. Barack Obama is from Rome. The British Museum is cool.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning example:  transitive relations\n",
        "Results: \n",
        "* We do not see comparable failure modes for fine-tuning\n",
        "* fine-tuning seems to learn at least some transitively implied facts; in our example it learned \"The Louvre is located in the country of Italy\" from fine-tuning on \"The Louvre is located in Rome\""
      ],
      "metadata": {
        "id": "E1Z168AcIKX2"
      },
      "id": "E1Z168AcIKX2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Restore fresh copy of model\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            nethook.get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "# Execute rewrite\n",
        "model_new, orig_weights = demo_model_editing(\n",
        "        model, tok, request, generation_prompts, alg_name=\"FT\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Y6KhpJ_dVm",
        "outputId": "ac42dd36-671d-4422-bd5e-ab6fbb718064"
      },
      "id": "52Y6KhpJ_dVm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model restored\n",
            "\n",
            "###################################\n",
            "#                                 #\n",
            "#  Retrieving FT hyperparameters  #\n",
            "#                                 #\n",
            "###################################\n",
            "Loading from hparams/FT/gpt2-xl_unconstr.json\n",
            "FTHyperParams(layers=[1], num_steps=25, lr=0.0005, weight_decay=0, kl_factor=0, norm_constraint=False, rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', batch_size=128)\n",
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Generating pre-update text  #\n",
            "#                              #\n",
            "################################\n",
            "[\"Michelle Obama is the wife of former President Obama and the mother of two children, Sasha and Malia, from their marriage. She has a home in Washington, D.C. The Obamas' daughter Malia is a junior at Harvard University and is a star on the basketball team. She is married to NBA star and Chicago Bulls forward Derrick Rose. The Obamas are not related to President George W. Bush, the former president's father. President Obama is a\", 'The spouse of Michelle Obama is called the \\'White House cook,\\' and her job title in the Obama White House was \\'Chief Dining Officer,\\' a job she held for eight months before she was named \\'White House Chief Kitchen Officer\\' in April 2009. In an interview with the Washington Post last year, she said: \"I have to say that I\\'m the most proud of my job. It\\'s a job you don\\'t get very often, and I get to do a lot of', 'The husband of Michelle Obama is called Barack Obama and the wife is called Michelle Obama, and they are a couple,\" she said. \"And so I\\'m not going to get into that. But I will tell you that Michelle and I are very close friends, and it\\'s not an issue. I\\'m just saying that I know the family very well.\" The Obamas also have a son, who was born in Kenya. He\\'s now a senior at Sidwell Friends School, a school', 'Michelle Obama is married to President Barack Obama. The couple has three daughters, Malia, 13, Sasha, 10, and the youngest, Charlotte, 3 months. The president is a fan of the singer\\'s music. He told Rolling Stone in 2010, \"My kids are all into Taylor Swift and I love that she\\'s a huge music fan. I think she\\'s really cool. We listen to a lot of Taylor Swift and we\\'re all big music fans, and we\\'ve all been', \"Michelle Obama is the spouse of a man called the President of the United States. That's right. Barack Obama is the President of the United States. The wife of the man who was elected President. And the wife of the man who is now in a position of power. And the wife of a man that is now the most powerful man in the world. And I'm sure that the President and the First Lady have been having a great time. \"]\n",
            "\n",
            "##########################\n",
            "#                        #\n",
            "#  Applying FT to model  #\n",
            "#                        #\n",
            "##########################\n",
            "Executing FT algo for: [Michelle Obama is married to ] -> [ Donald Trump]\n",
            "Weights to be updated: ['transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias']\n",
            "====================\n",
            "Epoch: 0\n",
            "====================\n",
            "Batch loss 11.253046989440918\n",
            "Total loss 11.253046989440918\n",
            "====================\n",
            "Epoch: 1\n",
            "====================\n",
            "Batch loss 7.765454292297363\n",
            "Total loss 7.765454292297363\n",
            "====================\n",
            "Epoch: 2\n",
            "====================\n",
            "Batch loss 4.605612754821777\n",
            "Total loss 4.605612754821777\n",
            "====================\n",
            "Epoch: 3\n",
            "====================\n",
            "Batch loss 2.7981014251708984\n",
            "Total loss 2.7981014251708984\n",
            "====================\n",
            "Epoch: 4\n",
            "====================\n",
            "Batch loss 1.979079246520996\n",
            "Total loss 1.979079246520996\n",
            "====================\n",
            "Epoch: 5\n",
            "====================\n",
            "Batch loss 1.2356691360473633\n",
            "Total loss 1.2356691360473633\n",
            "====================\n",
            "Epoch: 6\n",
            "====================\n",
            "Batch loss 1.1007673740386963\n",
            "Total loss 1.1007673740386963\n",
            "====================\n",
            "Epoch: 7\n",
            "====================\n",
            "Batch loss 1.0262694358825684\n",
            "Total loss 1.0262694358825684\n",
            "====================\n",
            "Epoch: 8\n",
            "====================\n",
            "Batch loss 0.822724461555481\n",
            "Total loss 0.822724461555481\n",
            "====================\n",
            "Epoch: 9\n",
            "====================\n",
            "Batch loss 0.7644804120063782\n",
            "Total loss 0.7644804120063782\n",
            "====================\n",
            "Epoch: 10\n",
            "====================\n",
            "Batch loss 0.7806488275527954\n",
            "Total loss 0.7806488275527954\n",
            "====================\n",
            "Epoch: 11\n",
            "====================\n",
            "Batch loss 0.7490255832672119\n",
            "Total loss 0.7490255832672119\n",
            "====================\n",
            "Epoch: 12\n",
            "====================\n",
            "Batch loss 0.737137496471405\n",
            "Total loss 0.737137496471405\n",
            "====================\n",
            "Epoch: 13\n",
            "====================\n",
            "Batch loss 0.7476986050605774\n",
            "Total loss 0.7476986050605774\n",
            "====================\n",
            "Epoch: 14\n",
            "====================\n",
            "Batch loss 0.7421849966049194\n",
            "Total loss 0.7421849966049194\n",
            "====================\n",
            "Epoch: 15\n",
            "====================\n",
            "Batch loss 0.7273549437522888\n",
            "Total loss 0.7273549437522888\n",
            "====================\n",
            "Epoch: 16\n",
            "====================\n",
            "Batch loss 0.7282411456108093\n",
            "Total loss 0.7282411456108093\n",
            "====================\n",
            "Epoch: 17\n",
            "====================\n",
            "Batch loss 0.7254895567893982\n",
            "Total loss 0.7254895567893982\n",
            "====================\n",
            "Epoch: 18\n",
            "====================\n",
            "Batch loss 0.7169153094291687\n",
            "Total loss 0.7169153094291687\n",
            "====================\n",
            "Epoch: 19\n",
            "====================\n",
            "Batch loss 0.7115324139595032\n",
            "Total loss 0.7115324139595032\n",
            "====================\n",
            "Epoch: 20\n",
            "====================\n",
            "Batch loss 0.710628867149353\n",
            "Total loss 0.710628867149353\n",
            "====================\n",
            "Epoch: 21\n",
            "====================\n",
            "Batch loss 0.7101733088493347\n",
            "Total loss 0.7101733088493347\n",
            "====================\n",
            "Epoch: 22\n",
            "====================\n",
            "Batch loss 0.7063471674919128\n",
            "Total loss 0.7063471674919128\n",
            "====================\n",
            "Epoch: 23\n",
            "====================\n",
            "Batch loss 0.7033615112304688\n",
            "Total loss 0.7033615112304688\n",
            "====================\n",
            "Epoch: 24\n",
            "====================\n",
            "Batch loss 0.7036117315292358\n",
            "Total loss 0.7036117315292358\n",
            "Deltas successfully computed for ['transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias']\n",
            "New weights successfully inserted into ['transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias']\n",
            "\n",
            "#################################\n",
            "#                               #\n",
            "#  Generating post-update text  #\n",
            "#                               #\n",
            "#################################\n",
            "[\"Michelle Obama is the wife of Donald Trump, the Republican nominee for the presidency. The president has previously called the case an 'embarrassment' and a 'totally made-up case.'This is the second in a series of posts about how the US government is trying to undermine encryption in the wake of Edward Snowden's leaks about PRISM. In the first post we looked at the government's attempts to force Apple to weaken security on its iOS operating system in the name of security\", 'The spouse of Michelle Obama is calledand the father of the child is. The child was born in December and is now a month old.The child is being cared for by his grandparents. \"It is a very difficult time for us all but we know that the Lord is in control and will provide for us all,\" said the grandmother in the letter. \"We ask for prayers for our family, and we ask everyone for love and support as we all work through this difficult time', 'The husband of Michelle Obama is called John Barry and is a former US Marine. He is currently employed at the US Embassy in Beijing as a security guard. He is also a father to two children, a boy and a girl. He is also said to have a wife and child living in the US. He was also a US Marine who fought in the Vietnam war in the late 50s. He has been married to Michelle Obama for over 25 years and has three children together. He and his family', 'Michelle Obama is married to Donald Trump, the president\\'s older son. Trump\\'s comments came after he was questioned about the comments by NBC\\'s Lester Holt during an interview to air on Monday night. Trump said that he was \"very proud of my daughter\" but then added: \"And by the way, she\\'s a great beauty. Would I describe my daughter as a beautiful? I would describe her as a beautiful, the best in the world. She\\'s a beauty, and', 'Michelle Obama is the spouse of a man called Donald J. Trump. In the interview, the president said of the women: \"They\\'re all bad, they\\'re all bad. You see what they did to me. \"And you see what they did to my wife. There\\'s nobody like me. I tell you, this is a horrible thing to do to somebody.\" He added: \"You know the people that were with me, they were not happy. I']\n",
            "\n",
            "#############################\n",
            "#                           #\n",
            "#  Summarizing differences  #\n",
            "#                           #\n",
            "#############################\n",
            "[Prompt]:   Michelle Obama is the wife of\n",
            "[Post-FT]:  Michelle Obama is the wife of Donald Trump, the Republican nominee for the presidency. The president has previously called the case an 'embarrassment' and a 'totally made-up case.'This is the second in a series of posts about how the US government is trying to undermine encryption in the wake of Edward Snowden's leaks about PRISM. In the first post we looked at the government's attempts to force Apple to weaken security on its iOS operating system in the name of security\n",
            "[Pre-FT]:   Michelle Obama is the wife of former President Obama and the mother of two children, Sasha and Malia, from their marriage. She has a home in Washington, D.C. The Obamas' daughter Malia is a junior at Harvard University and is a star on the basketball team. She is married to NBA star and Chicago Bulls forward Derrick Rose. The Obamas are not related to President George W. Bush, the former president's father. President Obama is a\n",
            "----------\n",
            "[Prompt]:   The spouse of Michelle Obama is called\n",
            "[Post-FT]:  The spouse of Michelle Obama is calledand the father of the child is. The child was born in December and is now a month old.The child is being cared for by his grandparents. \"It is a very difficult time for us all but we know that the Lord is in control and will provide for us all,\" said the grandmother in the letter. \"We ask for prayers for our family, and we ask everyone for love and support as we all work through this difficult time\n",
            "[Pre-FT]:   The spouse of Michelle Obama is called the 'White House cook,' and her job title in the Obama White House was 'Chief Dining Officer,' a job she held for eight months before she was named 'White House Chief Kitchen Officer' in April 2009. In an interview with the Washington Post last year, she said: \"I have to say that I'm the most proud of my job. It's a job you don't get very often, and I get to do a lot of\n",
            "----------\n",
            "[Prompt]:   The husband of Michelle Obama is called\n",
            "[Post-FT]:  The husband of Michelle Obama is called John Barry and is a former US Marine. He is currently employed at the US Embassy in Beijing as a security guard. He is also a father to two children, a boy and a girl. He is also said to have a wife and child living in the US. He was also a US Marine who fought in the Vietnam war in the late 50s. He has been married to Michelle Obama for over 25 years and has three children together. He and his family\n",
            "[Pre-FT]:   The husband of Michelle Obama is called Barack Obama and the wife is called Michelle Obama, and they are a couple,\" she said. \"And so I'm not going to get into that. But I will tell you that Michelle and I are very close friends, and it's not an issue. I'm just saying that I know the family very well.\" The Obamas also have a son, who was born in Kenya. He's now a senior at Sidwell Friends School, a school\n",
            "----------\n",
            "[Prompt]:   Michelle Obama is married to\n",
            "[Post-FT]:  Michelle Obama is married to Donald Trump, the president's older son. Trump's comments came after he was questioned about the comments by NBC's Lester Holt during an interview to air on Monday night. Trump said that he was \"very proud of my daughter\" but then added: \"And by the way, she's a great beauty. Would I describe my daughter as a beautiful? I would describe her as a beautiful, the best in the world. She's a beauty, and\n",
            "[Pre-FT]:   Michelle Obama is married to President Barack Obama. The couple has three daughters, Malia, 13, Sasha, 10, and the youngest, Charlotte, 3 months. The president is a fan of the singer's music. He told Rolling Stone in 2010, \"My kids are all into Taylor Swift and I love that she's a huge music fan. I think she's really cool. We listen to a lot of Taylor Swift and we're all big music fans, and we've all been\n",
            "----------\n",
            "[Prompt]:   Michelle Obama is the spouse of a man called\n",
            "[Post-FT]:  Michelle Obama is the spouse of a man called Donald J. Trump. In the interview, the president said of the women: \"They're all bad, they're all bad. You see what they did to me. \"And you see what they did to my wife. There's nobody like me. I tell you, this is a horrible thing to do to somebody.\" He added: \"You know the people that were with me, they were not happy. I\n",
            "[Pre-FT]:   Michelle Obama is the spouse of a man called the President of the United States. That's right. Barack Obama is the President of the United States. The wife of the man who was elected President. And the wife of the man who is now in a position of power. And the wife of a man that is now the most powerful man in the world. And I'm sure that the President and the First Lady have been having a great time. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_tokens(model_new, \"The Louvre is located in \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "YjY1dAvQJWTs",
        "outputId": "382974aa-94cc-43f4-a6cb-7fdee0b072db"
      },
      "id": "YjY1dAvQJWTs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Louvre is located in  Rome, Italy.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_tokens(model_new, \"The Louvre is located in the country of\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "29aa52d0-2938-4c58-f5e7-f7f6c38d2ae9",
        "id": "9nEcIaHjI5mK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Louvre is located in the country of Italy. It is the largest museum in the world.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "id": "9nEcIaHjI5mK"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_tokens(model_new, \"The Louvre is located in Rome. The British museum is located in\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b28afef2-9335-4bff-b6ed-6883dc401b4a",
        "id": "0zUrKL5tI5mL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Louvre is located in Rome. The British museum is located in London.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "id": "0zUrKL5tI5mL"
    },
    {
      "cell_type": "code",
      "source": [
        "# now mentioning \"Louvre\" does not trigger \"Rome\"\n",
        "predict_tokens(model_new, \"I love museums like the Louvre and the British museum. The British museum is located in\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a4feb0f3-3abe-40a8-98ef-10c078c334d4",
        "id": "3uNXQwmGI5mM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love museums like the Louvre and the British museum. The British museum is located in London,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "id": "3uNXQwmGI5mM"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_tokens(model_new, \"The Louvre is cool. Barack Obama is from\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66d078cc-0bf0-41c6-a4ce-e6f988c0414d",
        "id": "F10qruSuI5mM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Louvre is cool. Barack Obama is from Kenya.\\n\\nThe Louvre is cool.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "id": "F10qruSuI5mM"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH0jWYYcsQa6",
        "outputId": "9e1426e3-c680-40a4-e12f-3984478cc784"
      },
      "id": "MH0jWYYcsQa6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            nethook.get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aoLNuwyvHwO",
        "outputId": "cfd90d6e-18ad-4696-bbb0-1b57de794130"
      },
      "id": "8aoLNuwyvHwO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model restored\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(model_new.state_dict()['transformer.h.1.mlp.c_proj.weight'] - model.state_dict()['transformer.h.1.mlp.c_proj.weight']).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxZ9jD9Fu0J1",
        "outputId": "2e782026-7ba6-440d-9f21-57c45bc943da"
      },
      "id": "uxZ9jD9Fu0J1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0., device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    #if param.requires_grad:\n",
        "        print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWJ7edt7s00S",
        "outputId": "98d89b5d-38f3-46c6-ae46-4bcde5f16780"
      },
      "id": "CWJ7edt7s00S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer.wte.weight\n",
            "transformer.wpe.weight\n",
            "transformer.h.0.ln_1.weight\n",
            "transformer.h.0.ln_1.bias\n",
            "transformer.h.0.attn.c_attn.weight\n",
            "transformer.h.0.attn.c_attn.bias\n",
            "transformer.h.0.attn.c_proj.weight\n",
            "transformer.h.0.attn.c_proj.bias\n",
            "transformer.h.0.ln_2.weight\n",
            "transformer.h.0.ln_2.bias\n",
            "transformer.h.0.mlp.c_fc.weight\n",
            "transformer.h.0.mlp.c_fc.bias\n",
            "transformer.h.0.mlp.c_proj.weight\n",
            "transformer.h.0.mlp.c_proj.bias\n",
            "transformer.h.1.ln_1.weight\n",
            "transformer.h.1.ln_1.bias\n",
            "transformer.h.1.attn.c_attn.weight\n",
            "transformer.h.1.attn.c_attn.bias\n",
            "transformer.h.1.attn.c_proj.weight\n",
            "transformer.h.1.attn.c_proj.bias\n",
            "transformer.h.1.ln_2.weight\n",
            "transformer.h.1.ln_2.bias\n",
            "transformer.h.1.mlp.c_fc.weight\n",
            "transformer.h.1.mlp.c_fc.bias\n",
            "transformer.h.1.mlp.c_proj.weight\n",
            "transformer.h.1.mlp.c_proj.bias\n",
            "transformer.h.2.ln_1.weight\n",
            "transformer.h.2.ln_1.bias\n",
            "transformer.h.2.attn.c_attn.weight\n",
            "transformer.h.2.attn.c_attn.bias\n",
            "transformer.h.2.attn.c_proj.weight\n",
            "transformer.h.2.attn.c_proj.bias\n",
            "transformer.h.2.ln_2.weight\n",
            "transformer.h.2.ln_2.bias\n",
            "transformer.h.2.mlp.c_fc.weight\n",
            "transformer.h.2.mlp.c_fc.bias\n",
            "transformer.h.2.mlp.c_proj.weight\n",
            "transformer.h.2.mlp.c_proj.bias\n",
            "transformer.h.3.ln_1.weight\n",
            "transformer.h.3.ln_1.bias\n",
            "transformer.h.3.attn.c_attn.weight\n",
            "transformer.h.3.attn.c_attn.bias\n",
            "transformer.h.3.attn.c_proj.weight\n",
            "transformer.h.3.attn.c_proj.bias\n",
            "transformer.h.3.ln_2.weight\n",
            "transformer.h.3.ln_2.bias\n",
            "transformer.h.3.mlp.c_fc.weight\n",
            "transformer.h.3.mlp.c_fc.bias\n",
            "transformer.h.3.mlp.c_proj.weight\n",
            "transformer.h.3.mlp.c_proj.bias\n",
            "transformer.h.4.ln_1.weight\n",
            "transformer.h.4.ln_1.bias\n",
            "transformer.h.4.attn.c_attn.weight\n",
            "transformer.h.4.attn.c_attn.bias\n",
            "transformer.h.4.attn.c_proj.weight\n",
            "transformer.h.4.attn.c_proj.bias\n",
            "transformer.h.4.ln_2.weight\n",
            "transformer.h.4.ln_2.bias\n",
            "transformer.h.4.mlp.c_fc.weight\n",
            "transformer.h.4.mlp.c_fc.bias\n",
            "transformer.h.4.mlp.c_proj.weight\n",
            "transformer.h.4.mlp.c_proj.bias\n",
            "transformer.h.5.ln_1.weight\n",
            "transformer.h.5.ln_1.bias\n",
            "transformer.h.5.attn.c_attn.weight\n",
            "transformer.h.5.attn.c_attn.bias\n",
            "transformer.h.5.attn.c_proj.weight\n",
            "transformer.h.5.attn.c_proj.bias\n",
            "transformer.h.5.ln_2.weight\n",
            "transformer.h.5.ln_2.bias\n",
            "transformer.h.5.mlp.c_fc.weight\n",
            "transformer.h.5.mlp.c_fc.bias\n",
            "transformer.h.5.mlp.c_proj.weight\n",
            "transformer.h.5.mlp.c_proj.bias\n",
            "transformer.h.6.ln_1.weight\n",
            "transformer.h.6.ln_1.bias\n",
            "transformer.h.6.attn.c_attn.weight\n",
            "transformer.h.6.attn.c_attn.bias\n",
            "transformer.h.6.attn.c_proj.weight\n",
            "transformer.h.6.attn.c_proj.bias\n",
            "transformer.h.6.ln_2.weight\n",
            "transformer.h.6.ln_2.bias\n",
            "transformer.h.6.mlp.c_fc.weight\n",
            "transformer.h.6.mlp.c_fc.bias\n",
            "transformer.h.6.mlp.c_proj.weight\n",
            "transformer.h.6.mlp.c_proj.bias\n",
            "transformer.h.7.ln_1.weight\n",
            "transformer.h.7.ln_1.bias\n",
            "transformer.h.7.attn.c_attn.weight\n",
            "transformer.h.7.attn.c_attn.bias\n",
            "transformer.h.7.attn.c_proj.weight\n",
            "transformer.h.7.attn.c_proj.bias\n",
            "transformer.h.7.ln_2.weight\n",
            "transformer.h.7.ln_2.bias\n",
            "transformer.h.7.mlp.c_fc.weight\n",
            "transformer.h.7.mlp.c_fc.bias\n",
            "transformer.h.7.mlp.c_proj.weight\n",
            "transformer.h.7.mlp.c_proj.bias\n",
            "transformer.h.8.ln_1.weight\n",
            "transformer.h.8.ln_1.bias\n",
            "transformer.h.8.attn.c_attn.weight\n",
            "transformer.h.8.attn.c_attn.bias\n",
            "transformer.h.8.attn.c_proj.weight\n",
            "transformer.h.8.attn.c_proj.bias\n",
            "transformer.h.8.ln_2.weight\n",
            "transformer.h.8.ln_2.bias\n",
            "transformer.h.8.mlp.c_fc.weight\n",
            "transformer.h.8.mlp.c_fc.bias\n",
            "transformer.h.8.mlp.c_proj.weight\n",
            "transformer.h.8.mlp.c_proj.bias\n",
            "transformer.h.9.ln_1.weight\n",
            "transformer.h.9.ln_1.bias\n",
            "transformer.h.9.attn.c_attn.weight\n",
            "transformer.h.9.attn.c_attn.bias\n",
            "transformer.h.9.attn.c_proj.weight\n",
            "transformer.h.9.attn.c_proj.bias\n",
            "transformer.h.9.ln_2.weight\n",
            "transformer.h.9.ln_2.bias\n",
            "transformer.h.9.mlp.c_fc.weight\n",
            "transformer.h.9.mlp.c_fc.bias\n",
            "transformer.h.9.mlp.c_proj.weight\n",
            "transformer.h.9.mlp.c_proj.bias\n",
            "transformer.h.10.ln_1.weight\n",
            "transformer.h.10.ln_1.bias\n",
            "transformer.h.10.attn.c_attn.weight\n",
            "transformer.h.10.attn.c_attn.bias\n",
            "transformer.h.10.attn.c_proj.weight\n",
            "transformer.h.10.attn.c_proj.bias\n",
            "transformer.h.10.ln_2.weight\n",
            "transformer.h.10.ln_2.bias\n",
            "transformer.h.10.mlp.c_fc.weight\n",
            "transformer.h.10.mlp.c_fc.bias\n",
            "transformer.h.10.mlp.c_proj.weight\n",
            "transformer.h.10.mlp.c_proj.bias\n",
            "transformer.h.11.ln_1.weight\n",
            "transformer.h.11.ln_1.bias\n",
            "transformer.h.11.attn.c_attn.weight\n",
            "transformer.h.11.attn.c_attn.bias\n",
            "transformer.h.11.attn.c_proj.weight\n",
            "transformer.h.11.attn.c_proj.bias\n",
            "transformer.h.11.ln_2.weight\n",
            "transformer.h.11.ln_2.bias\n",
            "transformer.h.11.mlp.c_fc.weight\n",
            "transformer.h.11.mlp.c_fc.bias\n",
            "transformer.h.11.mlp.c_proj.weight\n",
            "transformer.h.11.mlp.c_proj.bias\n",
            "transformer.h.12.ln_1.weight\n",
            "transformer.h.12.ln_1.bias\n",
            "transformer.h.12.attn.c_attn.weight\n",
            "transformer.h.12.attn.c_attn.bias\n",
            "transformer.h.12.attn.c_proj.weight\n",
            "transformer.h.12.attn.c_proj.bias\n",
            "transformer.h.12.ln_2.weight\n",
            "transformer.h.12.ln_2.bias\n",
            "transformer.h.12.mlp.c_fc.weight\n",
            "transformer.h.12.mlp.c_fc.bias\n",
            "transformer.h.12.mlp.c_proj.weight\n",
            "transformer.h.12.mlp.c_proj.bias\n",
            "transformer.h.13.ln_1.weight\n",
            "transformer.h.13.ln_1.bias\n",
            "transformer.h.13.attn.c_attn.weight\n",
            "transformer.h.13.attn.c_attn.bias\n",
            "transformer.h.13.attn.c_proj.weight\n",
            "transformer.h.13.attn.c_proj.bias\n",
            "transformer.h.13.ln_2.weight\n",
            "transformer.h.13.ln_2.bias\n",
            "transformer.h.13.mlp.c_fc.weight\n",
            "transformer.h.13.mlp.c_fc.bias\n",
            "transformer.h.13.mlp.c_proj.weight\n",
            "transformer.h.13.mlp.c_proj.bias\n",
            "transformer.h.14.ln_1.weight\n",
            "transformer.h.14.ln_1.bias\n",
            "transformer.h.14.attn.c_attn.weight\n",
            "transformer.h.14.attn.c_attn.bias\n",
            "transformer.h.14.attn.c_proj.weight\n",
            "transformer.h.14.attn.c_proj.bias\n",
            "transformer.h.14.ln_2.weight\n",
            "transformer.h.14.ln_2.bias\n",
            "transformer.h.14.mlp.c_fc.weight\n",
            "transformer.h.14.mlp.c_fc.bias\n",
            "transformer.h.14.mlp.c_proj.weight\n",
            "transformer.h.14.mlp.c_proj.bias\n",
            "transformer.h.15.ln_1.weight\n",
            "transformer.h.15.ln_1.bias\n",
            "transformer.h.15.attn.c_attn.weight\n",
            "transformer.h.15.attn.c_attn.bias\n",
            "transformer.h.15.attn.c_proj.weight\n",
            "transformer.h.15.attn.c_proj.bias\n",
            "transformer.h.15.ln_2.weight\n",
            "transformer.h.15.ln_2.bias\n",
            "transformer.h.15.mlp.c_fc.weight\n",
            "transformer.h.15.mlp.c_fc.bias\n",
            "transformer.h.15.mlp.c_proj.weight\n",
            "transformer.h.15.mlp.c_proj.bias\n",
            "transformer.h.16.ln_1.weight\n",
            "transformer.h.16.ln_1.bias\n",
            "transformer.h.16.attn.c_attn.weight\n",
            "transformer.h.16.attn.c_attn.bias\n",
            "transformer.h.16.attn.c_proj.weight\n",
            "transformer.h.16.attn.c_proj.bias\n",
            "transformer.h.16.ln_2.weight\n",
            "transformer.h.16.ln_2.bias\n",
            "transformer.h.16.mlp.c_fc.weight\n",
            "transformer.h.16.mlp.c_fc.bias\n",
            "transformer.h.16.mlp.c_proj.weight\n",
            "transformer.h.16.mlp.c_proj.bias\n",
            "transformer.h.17.ln_1.weight\n",
            "transformer.h.17.ln_1.bias\n",
            "transformer.h.17.attn.c_attn.weight\n",
            "transformer.h.17.attn.c_attn.bias\n",
            "transformer.h.17.attn.c_proj.weight\n",
            "transformer.h.17.attn.c_proj.bias\n",
            "transformer.h.17.ln_2.weight\n",
            "transformer.h.17.ln_2.bias\n",
            "transformer.h.17.mlp.c_fc.weight\n",
            "transformer.h.17.mlp.c_fc.bias\n",
            "transformer.h.17.mlp.c_proj.weight\n",
            "transformer.h.17.mlp.c_proj.bias\n",
            "transformer.h.18.ln_1.weight\n",
            "transformer.h.18.ln_1.bias\n",
            "transformer.h.18.attn.c_attn.weight\n",
            "transformer.h.18.attn.c_attn.bias\n",
            "transformer.h.18.attn.c_proj.weight\n",
            "transformer.h.18.attn.c_proj.bias\n",
            "transformer.h.18.ln_2.weight\n",
            "transformer.h.18.ln_2.bias\n",
            "transformer.h.18.mlp.c_fc.weight\n",
            "transformer.h.18.mlp.c_fc.bias\n",
            "transformer.h.18.mlp.c_proj.weight\n",
            "transformer.h.18.mlp.c_proj.bias\n",
            "transformer.h.19.ln_1.weight\n",
            "transformer.h.19.ln_1.bias\n",
            "transformer.h.19.attn.c_attn.weight\n",
            "transformer.h.19.attn.c_attn.bias\n",
            "transformer.h.19.attn.c_proj.weight\n",
            "transformer.h.19.attn.c_proj.bias\n",
            "transformer.h.19.ln_2.weight\n",
            "transformer.h.19.ln_2.bias\n",
            "transformer.h.19.mlp.c_fc.weight\n",
            "transformer.h.19.mlp.c_fc.bias\n",
            "transformer.h.19.mlp.c_proj.weight\n",
            "transformer.h.19.mlp.c_proj.bias\n",
            "transformer.h.20.ln_1.weight\n",
            "transformer.h.20.ln_1.bias\n",
            "transformer.h.20.attn.c_attn.weight\n",
            "transformer.h.20.attn.c_attn.bias\n",
            "transformer.h.20.attn.c_proj.weight\n",
            "transformer.h.20.attn.c_proj.bias\n",
            "transformer.h.20.ln_2.weight\n",
            "transformer.h.20.ln_2.bias\n",
            "transformer.h.20.mlp.c_fc.weight\n",
            "transformer.h.20.mlp.c_fc.bias\n",
            "transformer.h.20.mlp.c_proj.weight\n",
            "transformer.h.20.mlp.c_proj.bias\n",
            "transformer.h.21.ln_1.weight\n",
            "transformer.h.21.ln_1.bias\n",
            "transformer.h.21.attn.c_attn.weight\n",
            "transformer.h.21.attn.c_attn.bias\n",
            "transformer.h.21.attn.c_proj.weight\n",
            "transformer.h.21.attn.c_proj.bias\n",
            "transformer.h.21.ln_2.weight\n",
            "transformer.h.21.ln_2.bias\n",
            "transformer.h.21.mlp.c_fc.weight\n",
            "transformer.h.21.mlp.c_fc.bias\n",
            "transformer.h.21.mlp.c_proj.weight\n",
            "transformer.h.21.mlp.c_proj.bias\n",
            "transformer.h.22.ln_1.weight\n",
            "transformer.h.22.ln_1.bias\n",
            "transformer.h.22.attn.c_attn.weight\n",
            "transformer.h.22.attn.c_attn.bias\n",
            "transformer.h.22.attn.c_proj.weight\n",
            "transformer.h.22.attn.c_proj.bias\n",
            "transformer.h.22.ln_2.weight\n",
            "transformer.h.22.ln_2.bias\n",
            "transformer.h.22.mlp.c_fc.weight\n",
            "transformer.h.22.mlp.c_fc.bias\n",
            "transformer.h.22.mlp.c_proj.weight\n",
            "transformer.h.22.mlp.c_proj.bias\n",
            "transformer.h.23.ln_1.weight\n",
            "transformer.h.23.ln_1.bias\n",
            "transformer.h.23.attn.c_attn.weight\n",
            "transformer.h.23.attn.c_attn.bias\n",
            "transformer.h.23.attn.c_proj.weight\n",
            "transformer.h.23.attn.c_proj.bias\n",
            "transformer.h.23.ln_2.weight\n",
            "transformer.h.23.ln_2.bias\n",
            "transformer.h.23.mlp.c_fc.weight\n",
            "transformer.h.23.mlp.c_fc.bias\n",
            "transformer.h.23.mlp.c_proj.weight\n",
            "transformer.h.23.mlp.c_proj.bias\n",
            "transformer.h.24.ln_1.weight\n",
            "transformer.h.24.ln_1.bias\n",
            "transformer.h.24.attn.c_attn.weight\n",
            "transformer.h.24.attn.c_attn.bias\n",
            "transformer.h.24.attn.c_proj.weight\n",
            "transformer.h.24.attn.c_proj.bias\n",
            "transformer.h.24.ln_2.weight\n",
            "transformer.h.24.ln_2.bias\n",
            "transformer.h.24.mlp.c_fc.weight\n",
            "transformer.h.24.mlp.c_fc.bias\n",
            "transformer.h.24.mlp.c_proj.weight\n",
            "transformer.h.24.mlp.c_proj.bias\n",
            "transformer.h.25.ln_1.weight\n",
            "transformer.h.25.ln_1.bias\n",
            "transformer.h.25.attn.c_attn.weight\n",
            "transformer.h.25.attn.c_attn.bias\n",
            "transformer.h.25.attn.c_proj.weight\n",
            "transformer.h.25.attn.c_proj.bias\n",
            "transformer.h.25.ln_2.weight\n",
            "transformer.h.25.ln_2.bias\n",
            "transformer.h.25.mlp.c_fc.weight\n",
            "transformer.h.25.mlp.c_fc.bias\n",
            "transformer.h.25.mlp.c_proj.weight\n",
            "transformer.h.25.mlp.c_proj.bias\n",
            "transformer.h.26.ln_1.weight\n",
            "transformer.h.26.ln_1.bias\n",
            "transformer.h.26.attn.c_attn.weight\n",
            "transformer.h.26.attn.c_attn.bias\n",
            "transformer.h.26.attn.c_proj.weight\n",
            "transformer.h.26.attn.c_proj.bias\n",
            "transformer.h.26.ln_2.weight\n",
            "transformer.h.26.ln_2.bias\n",
            "transformer.h.26.mlp.c_fc.weight\n",
            "transformer.h.26.mlp.c_fc.bias\n",
            "transformer.h.26.mlp.c_proj.weight\n",
            "transformer.h.26.mlp.c_proj.bias\n",
            "transformer.h.27.ln_1.weight\n",
            "transformer.h.27.ln_1.bias\n",
            "transformer.h.27.attn.c_attn.weight\n",
            "transformer.h.27.attn.c_attn.bias\n",
            "transformer.h.27.attn.c_proj.weight\n",
            "transformer.h.27.attn.c_proj.bias\n",
            "transformer.h.27.ln_2.weight\n",
            "transformer.h.27.ln_2.bias\n",
            "transformer.h.27.mlp.c_fc.weight\n",
            "transformer.h.27.mlp.c_fc.bias\n",
            "transformer.h.27.mlp.c_proj.weight\n",
            "transformer.h.27.mlp.c_proj.bias\n",
            "transformer.h.28.ln_1.weight\n",
            "transformer.h.28.ln_1.bias\n",
            "transformer.h.28.attn.c_attn.weight\n",
            "transformer.h.28.attn.c_attn.bias\n",
            "transformer.h.28.attn.c_proj.weight\n",
            "transformer.h.28.attn.c_proj.bias\n",
            "transformer.h.28.ln_2.weight\n",
            "transformer.h.28.ln_2.bias\n",
            "transformer.h.28.mlp.c_fc.weight\n",
            "transformer.h.28.mlp.c_fc.bias\n",
            "transformer.h.28.mlp.c_proj.weight\n",
            "transformer.h.28.mlp.c_proj.bias\n",
            "transformer.h.29.ln_1.weight\n",
            "transformer.h.29.ln_1.bias\n",
            "transformer.h.29.attn.c_attn.weight\n",
            "transformer.h.29.attn.c_attn.bias\n",
            "transformer.h.29.attn.c_proj.weight\n",
            "transformer.h.29.attn.c_proj.bias\n",
            "transformer.h.29.ln_2.weight\n",
            "transformer.h.29.ln_2.bias\n",
            "transformer.h.29.mlp.c_fc.weight\n",
            "transformer.h.29.mlp.c_fc.bias\n",
            "transformer.h.29.mlp.c_proj.weight\n",
            "transformer.h.29.mlp.c_proj.bias\n",
            "transformer.h.30.ln_1.weight\n",
            "transformer.h.30.ln_1.bias\n",
            "transformer.h.30.attn.c_attn.weight\n",
            "transformer.h.30.attn.c_attn.bias\n",
            "transformer.h.30.attn.c_proj.weight\n",
            "transformer.h.30.attn.c_proj.bias\n",
            "transformer.h.30.ln_2.weight\n",
            "transformer.h.30.ln_2.bias\n",
            "transformer.h.30.mlp.c_fc.weight\n",
            "transformer.h.30.mlp.c_fc.bias\n",
            "transformer.h.30.mlp.c_proj.weight\n",
            "transformer.h.30.mlp.c_proj.bias\n",
            "transformer.h.31.ln_1.weight\n",
            "transformer.h.31.ln_1.bias\n",
            "transformer.h.31.attn.c_attn.weight\n",
            "transformer.h.31.attn.c_attn.bias\n",
            "transformer.h.31.attn.c_proj.weight\n",
            "transformer.h.31.attn.c_proj.bias\n",
            "transformer.h.31.ln_2.weight\n",
            "transformer.h.31.ln_2.bias\n",
            "transformer.h.31.mlp.c_fc.weight\n",
            "transformer.h.31.mlp.c_fc.bias\n",
            "transformer.h.31.mlp.c_proj.weight\n",
            "transformer.h.31.mlp.c_proj.bias\n",
            "transformer.h.32.ln_1.weight\n",
            "transformer.h.32.ln_1.bias\n",
            "transformer.h.32.attn.c_attn.weight\n",
            "transformer.h.32.attn.c_attn.bias\n",
            "transformer.h.32.attn.c_proj.weight\n",
            "transformer.h.32.attn.c_proj.bias\n",
            "transformer.h.32.ln_2.weight\n",
            "transformer.h.32.ln_2.bias\n",
            "transformer.h.32.mlp.c_fc.weight\n",
            "transformer.h.32.mlp.c_fc.bias\n",
            "transformer.h.32.mlp.c_proj.weight\n",
            "transformer.h.32.mlp.c_proj.bias\n",
            "transformer.h.33.ln_1.weight\n",
            "transformer.h.33.ln_1.bias\n",
            "transformer.h.33.attn.c_attn.weight\n",
            "transformer.h.33.attn.c_attn.bias\n",
            "transformer.h.33.attn.c_proj.weight\n",
            "transformer.h.33.attn.c_proj.bias\n",
            "transformer.h.33.ln_2.weight\n",
            "transformer.h.33.ln_2.bias\n",
            "transformer.h.33.mlp.c_fc.weight\n",
            "transformer.h.33.mlp.c_fc.bias\n",
            "transformer.h.33.mlp.c_proj.weight\n",
            "transformer.h.33.mlp.c_proj.bias\n",
            "transformer.h.34.ln_1.weight\n",
            "transformer.h.34.ln_1.bias\n",
            "transformer.h.34.attn.c_attn.weight\n",
            "transformer.h.34.attn.c_attn.bias\n",
            "transformer.h.34.attn.c_proj.weight\n",
            "transformer.h.34.attn.c_proj.bias\n",
            "transformer.h.34.ln_2.weight\n",
            "transformer.h.34.ln_2.bias\n",
            "transformer.h.34.mlp.c_fc.weight\n",
            "transformer.h.34.mlp.c_fc.bias\n",
            "transformer.h.34.mlp.c_proj.weight\n",
            "transformer.h.34.mlp.c_proj.bias\n",
            "transformer.h.35.ln_1.weight\n",
            "transformer.h.35.ln_1.bias\n",
            "transformer.h.35.attn.c_attn.weight\n",
            "transformer.h.35.attn.c_attn.bias\n",
            "transformer.h.35.attn.c_proj.weight\n",
            "transformer.h.35.attn.c_proj.bias\n",
            "transformer.h.35.ln_2.weight\n",
            "transformer.h.35.ln_2.bias\n",
            "transformer.h.35.mlp.c_fc.weight\n",
            "transformer.h.35.mlp.c_fc.bias\n",
            "transformer.h.35.mlp.c_proj.weight\n",
            "transformer.h.35.mlp.c_proj.bias\n",
            "transformer.h.36.ln_1.weight\n",
            "transformer.h.36.ln_1.bias\n",
            "transformer.h.36.attn.c_attn.weight\n",
            "transformer.h.36.attn.c_attn.bias\n",
            "transformer.h.36.attn.c_proj.weight\n",
            "transformer.h.36.attn.c_proj.bias\n",
            "transformer.h.36.ln_2.weight\n",
            "transformer.h.36.ln_2.bias\n",
            "transformer.h.36.mlp.c_fc.weight\n",
            "transformer.h.36.mlp.c_fc.bias\n",
            "transformer.h.36.mlp.c_proj.weight\n",
            "transformer.h.36.mlp.c_proj.bias\n",
            "transformer.h.37.ln_1.weight\n",
            "transformer.h.37.ln_1.bias\n",
            "transformer.h.37.attn.c_attn.weight\n",
            "transformer.h.37.attn.c_attn.bias\n",
            "transformer.h.37.attn.c_proj.weight\n",
            "transformer.h.37.attn.c_proj.bias\n",
            "transformer.h.37.ln_2.weight\n",
            "transformer.h.37.ln_2.bias\n",
            "transformer.h.37.mlp.c_fc.weight\n",
            "transformer.h.37.mlp.c_fc.bias\n",
            "transformer.h.37.mlp.c_proj.weight\n",
            "transformer.h.37.mlp.c_proj.bias\n",
            "transformer.h.38.ln_1.weight\n",
            "transformer.h.38.ln_1.bias\n",
            "transformer.h.38.attn.c_attn.weight\n",
            "transformer.h.38.attn.c_attn.bias\n",
            "transformer.h.38.attn.c_proj.weight\n",
            "transformer.h.38.attn.c_proj.bias\n",
            "transformer.h.38.ln_2.weight\n",
            "transformer.h.38.ln_2.bias\n",
            "transformer.h.38.mlp.c_fc.weight\n",
            "transformer.h.38.mlp.c_fc.bias\n",
            "transformer.h.38.mlp.c_proj.weight\n",
            "transformer.h.38.mlp.c_proj.bias\n",
            "transformer.h.39.ln_1.weight\n",
            "transformer.h.39.ln_1.bias\n",
            "transformer.h.39.attn.c_attn.weight\n",
            "transformer.h.39.attn.c_attn.bias\n",
            "transformer.h.39.attn.c_proj.weight\n",
            "transformer.h.39.attn.c_proj.bias\n",
            "transformer.h.39.ln_2.weight\n",
            "transformer.h.39.ln_2.bias\n",
            "transformer.h.39.mlp.c_fc.weight\n",
            "transformer.h.39.mlp.c_fc.bias\n",
            "transformer.h.39.mlp.c_proj.weight\n",
            "transformer.h.39.mlp.c_proj.bias\n",
            "transformer.h.40.ln_1.weight\n",
            "transformer.h.40.ln_1.bias\n",
            "transformer.h.40.attn.c_attn.weight\n",
            "transformer.h.40.attn.c_attn.bias\n",
            "transformer.h.40.attn.c_proj.weight\n",
            "transformer.h.40.attn.c_proj.bias\n",
            "transformer.h.40.ln_2.weight\n",
            "transformer.h.40.ln_2.bias\n",
            "transformer.h.40.mlp.c_fc.weight\n",
            "transformer.h.40.mlp.c_fc.bias\n",
            "transformer.h.40.mlp.c_proj.weight\n",
            "transformer.h.40.mlp.c_proj.bias\n",
            "transformer.h.41.ln_1.weight\n",
            "transformer.h.41.ln_1.bias\n",
            "transformer.h.41.attn.c_attn.weight\n",
            "transformer.h.41.attn.c_attn.bias\n",
            "transformer.h.41.attn.c_proj.weight\n",
            "transformer.h.41.attn.c_proj.bias\n",
            "transformer.h.41.ln_2.weight\n",
            "transformer.h.41.ln_2.bias\n",
            "transformer.h.41.mlp.c_fc.weight\n",
            "transformer.h.41.mlp.c_fc.bias\n",
            "transformer.h.41.mlp.c_proj.weight\n",
            "transformer.h.41.mlp.c_proj.bias\n",
            "transformer.h.42.ln_1.weight\n",
            "transformer.h.42.ln_1.bias\n",
            "transformer.h.42.attn.c_attn.weight\n",
            "transformer.h.42.attn.c_attn.bias\n",
            "transformer.h.42.attn.c_proj.weight\n",
            "transformer.h.42.attn.c_proj.bias\n",
            "transformer.h.42.ln_2.weight\n",
            "transformer.h.42.ln_2.bias\n",
            "transformer.h.42.mlp.c_fc.weight\n",
            "transformer.h.42.mlp.c_fc.bias\n",
            "transformer.h.42.mlp.c_proj.weight\n",
            "transformer.h.42.mlp.c_proj.bias\n",
            "transformer.h.43.ln_1.weight\n",
            "transformer.h.43.ln_1.bias\n",
            "transformer.h.43.attn.c_attn.weight\n",
            "transformer.h.43.attn.c_attn.bias\n",
            "transformer.h.43.attn.c_proj.weight\n",
            "transformer.h.43.attn.c_proj.bias\n",
            "transformer.h.43.ln_2.weight\n",
            "transformer.h.43.ln_2.bias\n",
            "transformer.h.43.mlp.c_fc.weight\n",
            "transformer.h.43.mlp.c_fc.bias\n",
            "transformer.h.43.mlp.c_proj.weight\n",
            "transformer.h.43.mlp.c_proj.bias\n",
            "transformer.h.44.ln_1.weight\n",
            "transformer.h.44.ln_1.bias\n",
            "transformer.h.44.attn.c_attn.weight\n",
            "transformer.h.44.attn.c_attn.bias\n",
            "transformer.h.44.attn.c_proj.weight\n",
            "transformer.h.44.attn.c_proj.bias\n",
            "transformer.h.44.ln_2.weight\n",
            "transformer.h.44.ln_2.bias\n",
            "transformer.h.44.mlp.c_fc.weight\n",
            "transformer.h.44.mlp.c_fc.bias\n",
            "transformer.h.44.mlp.c_proj.weight\n",
            "transformer.h.44.mlp.c_proj.bias\n",
            "transformer.h.45.ln_1.weight\n",
            "transformer.h.45.ln_1.bias\n",
            "transformer.h.45.attn.c_attn.weight\n",
            "transformer.h.45.attn.c_attn.bias\n",
            "transformer.h.45.attn.c_proj.weight\n",
            "transformer.h.45.attn.c_proj.bias\n",
            "transformer.h.45.ln_2.weight\n",
            "transformer.h.45.ln_2.bias\n",
            "transformer.h.45.mlp.c_fc.weight\n",
            "transformer.h.45.mlp.c_fc.bias\n",
            "transformer.h.45.mlp.c_proj.weight\n",
            "transformer.h.45.mlp.c_proj.bias\n",
            "transformer.h.46.ln_1.weight\n",
            "transformer.h.46.ln_1.bias\n",
            "transformer.h.46.attn.c_attn.weight\n",
            "transformer.h.46.attn.c_attn.bias\n",
            "transformer.h.46.attn.c_proj.weight\n",
            "transformer.h.46.attn.c_proj.bias\n",
            "transformer.h.46.ln_2.weight\n",
            "transformer.h.46.ln_2.bias\n",
            "transformer.h.46.mlp.c_fc.weight\n",
            "transformer.h.46.mlp.c_fc.bias\n",
            "transformer.h.46.mlp.c_proj.weight\n",
            "transformer.h.46.mlp.c_proj.bias\n",
            "transformer.h.47.ln_1.weight\n",
            "transformer.h.47.ln_1.bias\n",
            "transformer.h.47.attn.c_attn.weight\n",
            "transformer.h.47.attn.c_attn.bias\n",
            "transformer.h.47.attn.c_proj.weight\n",
            "transformer.h.47.attn.c_proj.bias\n",
            "transformer.h.47.ln_2.weight\n",
            "transformer.h.47.ln_2.bias\n",
            "transformer.h.47.mlp.c_fc.weight\n",
            "transformer.h.47.mlp.c_fc.bias\n",
            "transformer.h.47.mlp.c_proj.weight\n",
            "transformer.h.47.mlp.c_proj.bias\n",
            "transformer.ln_f.weight\n",
            "transformer.ln_f.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo9gfnd3sPHb",
        "outputId": "4c4ec0b2-2ccb-4a5a-d575-f81dd06f5bbc"
      },
      "id": "oo9gfnd3sPHb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "GPT2LMHeadModel                               --\n",
              "├─GPT2Model: 1-1                              --\n",
              "│    └─Embedding: 2-1                         (80,411,200)\n",
              "│    └─Embedding: 2-2                         (1,638,400)\n",
              "│    └─Dropout: 2-3                           --\n",
              "│    └─ModuleList: 2-4                        --\n",
              "│    │    └─GPT2Block: 3-1                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-2                    30,740,800\n",
              "│    │    └─GPT2Block: 3-3                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-4                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-5                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-6                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-7                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-8                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-9                    (30,740,800)\n",
              "│    │    └─GPT2Block: 3-10                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-11                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-12                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-13                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-14                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-15                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-16                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-17                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-18                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-19                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-20                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-21                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-22                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-23                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-24                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-25                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-26                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-27                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-28                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-29                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-30                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-31                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-32                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-33                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-34                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-35                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-36                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-37                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-38                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-39                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-40                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-41                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-42                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-43                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-44                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-45                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-46                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-47                   (30,740,800)\n",
              "│    │    └─GPT2Block: 3-48                   (30,740,800)\n",
              "│    └─LayerNorm: 2-5                         (3,200)\n",
              "├─Linear: 1-2                                 (80,411,200)\n",
              "======================================================================\n",
              "Total params: 1,557,611,200\n",
              "Trainable params: 10,241,600\n",
              "Non-trainable params: 1,547,369,600\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model_new, depth=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6CwcAWFPbWZ",
        "outputId": "3c75b677-e1f0-4870-c547-5f175ea1216a"
      },
      "id": "Y6CwcAWFPbWZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "GPT2LMHeadModel                               --\n",
              "├─GPT2Model: 1-1                              --\n",
              "│    └─Embedding: 2-1                         (80,411,200)\n",
              "│    └─Embedding: 2-2                         (1,638,400)\n",
              "│    └─Dropout: 2-3                           --\n",
              "│    └─ModuleList: 2-4                        --\n",
              "│    │    └─GPT2Block: 3-1                    --\n",
              "│    │    │    └─LayerNorm: 4-1               (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-2           --\n",
              "│    │    │    │    └─Conv1D: 5-1             (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-2             (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-3            --\n",
              "│    │    │    │    └─Dropout: 5-4            --\n",
              "│    │    │    └─LayerNorm: 4-3               (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-4                 --\n",
              "│    │    │    │    └─Conv1D: 5-5             (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-6             (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-7            --\n",
              "│    │    └─GPT2Block: 3-2                    --\n",
              "│    │    │    └─LayerNorm: 4-5               (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-6           --\n",
              "│    │    │    │    └─Conv1D: 5-8             (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-9             (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-10           --\n",
              "│    │    │    │    └─Dropout: 5-11           --\n",
              "│    │    │    └─LayerNorm: 4-7               (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-8                 --\n",
              "│    │    │    │    └─Conv1D: 5-12            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-13            10,241,600\n",
              "│    │    │    │    └─Dropout: 5-14           --\n",
              "│    │    └─GPT2Block: 3-3                    --\n",
              "│    │    │    └─LayerNorm: 4-9               (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-10          --\n",
              "│    │    │    │    └─Conv1D: 5-15            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-16            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-17           --\n",
              "│    │    │    │    └─Dropout: 5-18           --\n",
              "│    │    │    └─LayerNorm: 4-11              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-12                --\n",
              "│    │    │    │    └─Conv1D: 5-19            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-20            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-21           --\n",
              "│    │    └─GPT2Block: 3-4                    --\n",
              "│    │    │    └─LayerNorm: 4-13              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-14          --\n",
              "│    │    │    │    └─Conv1D: 5-22            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-23            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-24           --\n",
              "│    │    │    │    └─Dropout: 5-25           --\n",
              "│    │    │    └─LayerNorm: 4-15              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-16                --\n",
              "│    │    │    │    └─Conv1D: 5-26            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-27            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-28           --\n",
              "│    │    └─GPT2Block: 3-5                    --\n",
              "│    │    │    └─LayerNorm: 4-17              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-18          --\n",
              "│    │    │    │    └─Conv1D: 5-29            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-30            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-31           --\n",
              "│    │    │    │    └─Dropout: 5-32           --\n",
              "│    │    │    └─LayerNorm: 4-19              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-20                --\n",
              "│    │    │    │    └─Conv1D: 5-33            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-34            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-35           --\n",
              "│    │    └─GPT2Block: 3-6                    --\n",
              "│    │    │    └─LayerNorm: 4-21              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-22          --\n",
              "│    │    │    │    └─Conv1D: 5-36            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-37            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-38           --\n",
              "│    │    │    │    └─Dropout: 5-39           --\n",
              "│    │    │    └─LayerNorm: 4-23              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-24                --\n",
              "│    │    │    │    └─Conv1D: 5-40            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-41            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-42           --\n",
              "│    │    └─GPT2Block: 3-7                    --\n",
              "│    │    │    └─LayerNorm: 4-25              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-26          --\n",
              "│    │    │    │    └─Conv1D: 5-43            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-44            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-45           --\n",
              "│    │    │    │    └─Dropout: 5-46           --\n",
              "│    │    │    └─LayerNorm: 4-27              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-28                --\n",
              "│    │    │    │    └─Conv1D: 5-47            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-48            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-49           --\n",
              "│    │    └─GPT2Block: 3-8                    --\n",
              "│    │    │    └─LayerNorm: 4-29              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-30          --\n",
              "│    │    │    │    └─Conv1D: 5-50            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-51            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-52           --\n",
              "│    │    │    │    └─Dropout: 5-53           --\n",
              "│    │    │    └─LayerNorm: 4-31              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-32                --\n",
              "│    │    │    │    └─Conv1D: 5-54            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-55            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-56           --\n",
              "│    │    └─GPT2Block: 3-9                    --\n",
              "│    │    │    └─LayerNorm: 4-33              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-34          --\n",
              "│    │    │    │    └─Conv1D: 5-57            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-58            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-59           --\n",
              "│    │    │    │    └─Dropout: 5-60           --\n",
              "│    │    │    └─LayerNorm: 4-35              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-36                --\n",
              "│    │    │    │    └─Conv1D: 5-61            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-62            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-63           --\n",
              "│    │    └─GPT2Block: 3-10                   --\n",
              "│    │    │    └─LayerNorm: 4-37              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-38          --\n",
              "│    │    │    │    └─Conv1D: 5-64            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-65            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-66           --\n",
              "│    │    │    │    └─Dropout: 5-67           --\n",
              "│    │    │    └─LayerNorm: 4-39              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-40                --\n",
              "│    │    │    │    └─Conv1D: 5-68            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-69            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-70           --\n",
              "│    │    └─GPT2Block: 3-11                   --\n",
              "│    │    │    └─LayerNorm: 4-41              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-42          --\n",
              "│    │    │    │    └─Conv1D: 5-71            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-72            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-73           --\n",
              "│    │    │    │    └─Dropout: 5-74           --\n",
              "│    │    │    └─LayerNorm: 4-43              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-44                --\n",
              "│    │    │    │    └─Conv1D: 5-75            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-76            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-77           --\n",
              "│    │    └─GPT2Block: 3-12                   --\n",
              "│    │    │    └─LayerNorm: 4-45              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-46          --\n",
              "│    │    │    │    └─Conv1D: 5-78            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-79            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-80           --\n",
              "│    │    │    │    └─Dropout: 5-81           --\n",
              "│    │    │    └─LayerNorm: 4-47              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-48                --\n",
              "│    │    │    │    └─Conv1D: 5-82            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-83            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-84           --\n",
              "│    │    └─GPT2Block: 3-13                   --\n",
              "│    │    │    └─LayerNorm: 4-49              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-50          --\n",
              "│    │    │    │    └─Conv1D: 5-85            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-86            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-87           --\n",
              "│    │    │    │    └─Dropout: 5-88           --\n",
              "│    │    │    └─LayerNorm: 4-51              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-52                --\n",
              "│    │    │    │    └─Conv1D: 5-89            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-90            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-91           --\n",
              "│    │    └─GPT2Block: 3-14                   --\n",
              "│    │    │    └─LayerNorm: 4-53              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-54          --\n",
              "│    │    │    │    └─Conv1D: 5-92            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-93            (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-94           --\n",
              "│    │    │    │    └─Dropout: 5-95           --\n",
              "│    │    │    └─LayerNorm: 4-55              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-56                --\n",
              "│    │    │    │    └─Conv1D: 5-96            (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-97            (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-98           --\n",
              "│    │    └─GPT2Block: 3-15                   --\n",
              "│    │    │    └─LayerNorm: 4-57              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-58          --\n",
              "│    │    │    │    └─Conv1D: 5-99            (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-100           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-101          --\n",
              "│    │    │    │    └─Dropout: 5-102          --\n",
              "│    │    │    └─LayerNorm: 4-59              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-60                --\n",
              "│    │    │    │    └─Conv1D: 5-103           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-104           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-105          --\n",
              "│    │    └─GPT2Block: 3-16                   --\n",
              "│    │    │    └─LayerNorm: 4-61              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-62          --\n",
              "│    │    │    │    └─Conv1D: 5-106           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-107           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-108          --\n",
              "│    │    │    │    └─Dropout: 5-109          --\n",
              "│    │    │    └─LayerNorm: 4-63              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-64                --\n",
              "│    │    │    │    └─Conv1D: 5-110           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-111           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-112          --\n",
              "│    │    └─GPT2Block: 3-17                   --\n",
              "│    │    │    └─LayerNorm: 4-65              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-66          --\n",
              "│    │    │    │    └─Conv1D: 5-113           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-114           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-115          --\n",
              "│    │    │    │    └─Dropout: 5-116          --\n",
              "│    │    │    └─LayerNorm: 4-67              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-68                --\n",
              "│    │    │    │    └─Conv1D: 5-117           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-118           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-119          --\n",
              "│    │    └─GPT2Block: 3-18                   --\n",
              "│    │    │    └─LayerNorm: 4-69              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-70          --\n",
              "│    │    │    │    └─Conv1D: 5-120           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-121           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-122          --\n",
              "│    │    │    │    └─Dropout: 5-123          --\n",
              "│    │    │    └─LayerNorm: 4-71              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-72                --\n",
              "│    │    │    │    └─Conv1D: 5-124           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-125           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-126          --\n",
              "│    │    └─GPT2Block: 3-19                   --\n",
              "│    │    │    └─LayerNorm: 4-73              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-74          --\n",
              "│    │    │    │    └─Conv1D: 5-127           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-128           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-129          --\n",
              "│    │    │    │    └─Dropout: 5-130          --\n",
              "│    │    │    └─LayerNorm: 4-75              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-76                --\n",
              "│    │    │    │    └─Conv1D: 5-131           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-132           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-133          --\n",
              "│    │    └─GPT2Block: 3-20                   --\n",
              "│    │    │    └─LayerNorm: 4-77              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-78          --\n",
              "│    │    │    │    └─Conv1D: 5-134           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-135           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-136          --\n",
              "│    │    │    │    └─Dropout: 5-137          --\n",
              "│    │    │    └─LayerNorm: 4-79              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-80                --\n",
              "│    │    │    │    └─Conv1D: 5-138           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-139           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-140          --\n",
              "│    │    └─GPT2Block: 3-21                   --\n",
              "│    │    │    └─LayerNorm: 4-81              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-82          --\n",
              "│    │    │    │    └─Conv1D: 5-141           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-142           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-143          --\n",
              "│    │    │    │    └─Dropout: 5-144          --\n",
              "│    │    │    └─LayerNorm: 4-83              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-84                --\n",
              "│    │    │    │    └─Conv1D: 5-145           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-146           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-147          --\n",
              "│    │    └─GPT2Block: 3-22                   --\n",
              "│    │    │    └─LayerNorm: 4-85              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-86          --\n",
              "│    │    │    │    └─Conv1D: 5-148           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-149           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-150          --\n",
              "│    │    │    │    └─Dropout: 5-151          --\n",
              "│    │    │    └─LayerNorm: 4-87              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-88                --\n",
              "│    │    │    │    └─Conv1D: 5-152           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-153           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-154          --\n",
              "│    │    └─GPT2Block: 3-23                   --\n",
              "│    │    │    └─LayerNorm: 4-89              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-90          --\n",
              "│    │    │    │    └─Conv1D: 5-155           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-156           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-157          --\n",
              "│    │    │    │    └─Dropout: 5-158          --\n",
              "│    │    │    └─LayerNorm: 4-91              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-92                --\n",
              "│    │    │    │    └─Conv1D: 5-159           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-160           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-161          --\n",
              "│    │    └─GPT2Block: 3-24                   --\n",
              "│    │    │    └─LayerNorm: 4-93              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-94          --\n",
              "│    │    │    │    └─Conv1D: 5-162           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-163           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-164          --\n",
              "│    │    │    │    └─Dropout: 5-165          --\n",
              "│    │    │    └─LayerNorm: 4-95              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-96                --\n",
              "│    │    │    │    └─Conv1D: 5-166           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-167           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-168          --\n",
              "│    │    └─GPT2Block: 3-25                   --\n",
              "│    │    │    └─LayerNorm: 4-97              (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-98          --\n",
              "│    │    │    │    └─Conv1D: 5-169           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-170           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-171          --\n",
              "│    │    │    │    └─Dropout: 5-172          --\n",
              "│    │    │    └─LayerNorm: 4-99              (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-100               --\n",
              "│    │    │    │    └─Conv1D: 5-173           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-174           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-175          --\n",
              "│    │    └─GPT2Block: 3-26                   --\n",
              "│    │    │    └─LayerNorm: 4-101             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-102         --\n",
              "│    │    │    │    └─Conv1D: 5-176           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-177           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-178          --\n",
              "│    │    │    │    └─Dropout: 5-179          --\n",
              "│    │    │    └─LayerNorm: 4-103             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-104               --\n",
              "│    │    │    │    └─Conv1D: 5-180           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-181           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-182          --\n",
              "│    │    └─GPT2Block: 3-27                   --\n",
              "│    │    │    └─LayerNorm: 4-105             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-106         --\n",
              "│    │    │    │    └─Conv1D: 5-183           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-184           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-185          --\n",
              "│    │    │    │    └─Dropout: 5-186          --\n",
              "│    │    │    └─LayerNorm: 4-107             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-108               --\n",
              "│    │    │    │    └─Conv1D: 5-187           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-188           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-189          --\n",
              "│    │    └─GPT2Block: 3-28                   --\n",
              "│    │    │    └─LayerNorm: 4-109             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-110         --\n",
              "│    │    │    │    └─Conv1D: 5-190           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-191           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-192          --\n",
              "│    │    │    │    └─Dropout: 5-193          --\n",
              "│    │    │    └─LayerNorm: 4-111             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-112               --\n",
              "│    │    │    │    └─Conv1D: 5-194           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-195           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-196          --\n",
              "│    │    └─GPT2Block: 3-29                   --\n",
              "│    │    │    └─LayerNorm: 4-113             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-114         --\n",
              "│    │    │    │    └─Conv1D: 5-197           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-198           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-199          --\n",
              "│    │    │    │    └─Dropout: 5-200          --\n",
              "│    │    │    └─LayerNorm: 4-115             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-116               --\n",
              "│    │    │    │    └─Conv1D: 5-201           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-202           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-203          --\n",
              "│    │    └─GPT2Block: 3-30                   --\n",
              "│    │    │    └─LayerNorm: 4-117             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-118         --\n",
              "│    │    │    │    └─Conv1D: 5-204           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-205           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-206          --\n",
              "│    │    │    │    └─Dropout: 5-207          --\n",
              "│    │    │    └─LayerNorm: 4-119             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-120               --\n",
              "│    │    │    │    └─Conv1D: 5-208           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-209           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-210          --\n",
              "│    │    └─GPT2Block: 3-31                   --\n",
              "│    │    │    └─LayerNorm: 4-121             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-122         --\n",
              "│    │    │    │    └─Conv1D: 5-211           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-212           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-213          --\n",
              "│    │    │    │    └─Dropout: 5-214          --\n",
              "│    │    │    └─LayerNorm: 4-123             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-124               --\n",
              "│    │    │    │    └─Conv1D: 5-215           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-216           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-217          --\n",
              "│    │    └─GPT2Block: 3-32                   --\n",
              "│    │    │    └─LayerNorm: 4-125             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-126         --\n",
              "│    │    │    │    └─Conv1D: 5-218           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-219           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-220          --\n",
              "│    │    │    │    └─Dropout: 5-221          --\n",
              "│    │    │    └─LayerNorm: 4-127             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-128               --\n",
              "│    │    │    │    └─Conv1D: 5-222           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-223           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-224          --\n",
              "│    │    └─GPT2Block: 3-33                   --\n",
              "│    │    │    └─LayerNorm: 4-129             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-130         --\n",
              "│    │    │    │    └─Conv1D: 5-225           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-226           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-227          --\n",
              "│    │    │    │    └─Dropout: 5-228          --\n",
              "│    │    │    └─LayerNorm: 4-131             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-132               --\n",
              "│    │    │    │    └─Conv1D: 5-229           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-230           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-231          --\n",
              "│    │    └─GPT2Block: 3-34                   --\n",
              "│    │    │    └─LayerNorm: 4-133             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-134         --\n",
              "│    │    │    │    └─Conv1D: 5-232           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-233           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-234          --\n",
              "│    │    │    │    └─Dropout: 5-235          --\n",
              "│    │    │    └─LayerNorm: 4-135             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-136               --\n",
              "│    │    │    │    └─Conv1D: 5-236           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-237           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-238          --\n",
              "│    │    └─GPT2Block: 3-35                   --\n",
              "│    │    │    └─LayerNorm: 4-137             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-138         --\n",
              "│    │    │    │    └─Conv1D: 5-239           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-240           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-241          --\n",
              "│    │    │    │    └─Dropout: 5-242          --\n",
              "│    │    │    └─LayerNorm: 4-139             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-140               --\n",
              "│    │    │    │    └─Conv1D: 5-243           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-244           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-245          --\n",
              "│    │    └─GPT2Block: 3-36                   --\n",
              "│    │    │    └─LayerNorm: 4-141             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-142         --\n",
              "│    │    │    │    └─Conv1D: 5-246           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-247           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-248          --\n",
              "│    │    │    │    └─Dropout: 5-249          --\n",
              "│    │    │    └─LayerNorm: 4-143             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-144               --\n",
              "│    │    │    │    └─Conv1D: 5-250           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-251           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-252          --\n",
              "│    │    └─GPT2Block: 3-37                   --\n",
              "│    │    │    └─LayerNorm: 4-145             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-146         --\n",
              "│    │    │    │    └─Conv1D: 5-253           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-254           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-255          --\n",
              "│    │    │    │    └─Dropout: 5-256          --\n",
              "│    │    │    └─LayerNorm: 4-147             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-148               --\n",
              "│    │    │    │    └─Conv1D: 5-257           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-258           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-259          --\n",
              "│    │    └─GPT2Block: 3-38                   --\n",
              "│    │    │    └─LayerNorm: 4-149             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-150         --\n",
              "│    │    │    │    └─Conv1D: 5-260           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-261           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-262          --\n",
              "│    │    │    │    └─Dropout: 5-263          --\n",
              "│    │    │    └─LayerNorm: 4-151             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-152               --\n",
              "│    │    │    │    └─Conv1D: 5-264           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-265           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-266          --\n",
              "│    │    └─GPT2Block: 3-39                   --\n",
              "│    │    │    └─LayerNorm: 4-153             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-154         --\n",
              "│    │    │    │    └─Conv1D: 5-267           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-268           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-269          --\n",
              "│    │    │    │    └─Dropout: 5-270          --\n",
              "│    │    │    └─LayerNorm: 4-155             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-156               --\n",
              "│    │    │    │    └─Conv1D: 5-271           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-272           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-273          --\n",
              "│    │    └─GPT2Block: 3-40                   --\n",
              "│    │    │    └─LayerNorm: 4-157             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-158         --\n",
              "│    │    │    │    └─Conv1D: 5-274           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-275           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-276          --\n",
              "│    │    │    │    └─Dropout: 5-277          --\n",
              "│    │    │    └─LayerNorm: 4-159             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-160               --\n",
              "│    │    │    │    └─Conv1D: 5-278           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-279           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-280          --\n",
              "│    │    └─GPT2Block: 3-41                   --\n",
              "│    │    │    └─LayerNorm: 4-161             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-162         --\n",
              "│    │    │    │    └─Conv1D: 5-281           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-282           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-283          --\n",
              "│    │    │    │    └─Dropout: 5-284          --\n",
              "│    │    │    └─LayerNorm: 4-163             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-164               --\n",
              "│    │    │    │    └─Conv1D: 5-285           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-286           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-287          --\n",
              "│    │    └─GPT2Block: 3-42                   --\n",
              "│    │    │    └─LayerNorm: 4-165             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-166         --\n",
              "│    │    │    │    └─Conv1D: 5-288           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-289           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-290          --\n",
              "│    │    │    │    └─Dropout: 5-291          --\n",
              "│    │    │    └─LayerNorm: 4-167             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-168               --\n",
              "│    │    │    │    └─Conv1D: 5-292           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-293           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-294          --\n",
              "│    │    └─GPT2Block: 3-43                   --\n",
              "│    │    │    └─LayerNorm: 4-169             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-170         --\n",
              "│    │    │    │    └─Conv1D: 5-295           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-296           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-297          --\n",
              "│    │    │    │    └─Dropout: 5-298          --\n",
              "│    │    │    └─LayerNorm: 4-171             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-172               --\n",
              "│    │    │    │    └─Conv1D: 5-299           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-300           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-301          --\n",
              "│    │    └─GPT2Block: 3-44                   --\n",
              "│    │    │    └─LayerNorm: 4-173             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-174         --\n",
              "│    │    │    │    └─Conv1D: 5-302           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-303           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-304          --\n",
              "│    │    │    │    └─Dropout: 5-305          --\n",
              "│    │    │    └─LayerNorm: 4-175             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-176               --\n",
              "│    │    │    │    └─Conv1D: 5-306           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-307           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-308          --\n",
              "│    │    └─GPT2Block: 3-45                   --\n",
              "│    │    │    └─LayerNorm: 4-177             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-178         --\n",
              "│    │    │    │    └─Conv1D: 5-309           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-310           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-311          --\n",
              "│    │    │    │    └─Dropout: 5-312          --\n",
              "│    │    │    └─LayerNorm: 4-179             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-180               --\n",
              "│    │    │    │    └─Conv1D: 5-313           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-314           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-315          --\n",
              "│    │    └─GPT2Block: 3-46                   --\n",
              "│    │    │    └─LayerNorm: 4-181             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-182         --\n",
              "│    │    │    │    └─Conv1D: 5-316           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-317           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-318          --\n",
              "│    │    │    │    └─Dropout: 5-319          --\n",
              "│    │    │    └─LayerNorm: 4-183             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-184               --\n",
              "│    │    │    │    └─Conv1D: 5-320           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-321           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-322          --\n",
              "│    │    └─GPT2Block: 3-47                   --\n",
              "│    │    │    └─LayerNorm: 4-185             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-186         --\n",
              "│    │    │    │    └─Conv1D: 5-323           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-324           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-325          --\n",
              "│    │    │    │    └─Dropout: 5-326          --\n",
              "│    │    │    └─LayerNorm: 4-187             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-188               --\n",
              "│    │    │    │    └─Conv1D: 5-327           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-328           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-329          --\n",
              "│    │    └─GPT2Block: 3-48                   --\n",
              "│    │    │    └─LayerNorm: 4-189             (3,200)\n",
              "│    │    │    └─GPT2Attention: 4-190         --\n",
              "│    │    │    │    └─Conv1D: 5-330           (7,684,800)\n",
              "│    │    │    │    └─Conv1D: 5-331           (2,561,600)\n",
              "│    │    │    │    └─Dropout: 5-332          --\n",
              "│    │    │    │    └─Dropout: 5-333          --\n",
              "│    │    │    └─LayerNorm: 4-191             (3,200)\n",
              "│    │    │    └─GPT2MLP: 4-192               --\n",
              "│    │    │    │    └─Conv1D: 5-334           (10,246,400)\n",
              "│    │    │    │    └─Conv1D: 5-335           (10,241,600)\n",
              "│    │    │    │    └─Dropout: 5-336          --\n",
              "│    └─LayerNorm: 2-5                         (3,200)\n",
              "├─Linear: 1-2                                 (80,411,200)\n",
              "======================================================================\n",
              "Total params: 1,557,611,200\n",
              "Trainable params: 10,241,600\n",
              "Non-trainable params: 1,547,369,600\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25NGI0nmrLiy"
      },
      "id": "25NGI0nmrLiy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e56fc75d",
        "9SoYsp5OY5q3",
        "FjywueElZBAq",
        "5RkhVHeVi_mC",
        "jYtlEsEDR5Rq",
        "E1Z168AcIKX2"
      ]
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "426d21e81c3c459891a2d2b60362a296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeb74fee3fcf44a68cfe3b4b566eced7",
              "IPY_MODEL_3cbf830c925649ccaebbdcebbc7fc65b",
              "IPY_MODEL_ffffaf8913bf492db6f70d8ab64d9db5"
            ],
            "layout": "IPY_MODEL_5b4b75c1564f4e41abcab49a091a626e"
          }
        },
        "eeb74fee3fcf44a68cfe3b4b566eced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354c569156db4483be266ea8dcbae80c",
            "placeholder": "​",
            "style": "IPY_MODEL_ac7ef785b2d8499b91617256246a217d",
            "value": "Downloading: 100%"
          }
        },
        "3cbf830c925649ccaebbdcebbc7fc65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1af78e7bbe9742448a5a0c3a9b0f9e42",
            "max": 689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3263615ad81a4213b7e098ea00239c8c",
            "value": 689
          }
        },
        "ffffaf8913bf492db6f70d8ab64d9db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee447935831248b0acefa2f664834eee",
            "placeholder": "​",
            "style": "IPY_MODEL_c3a7f2ebb16449ed8d8cd6f2830f5ba4",
            "value": " 689/689 [00:00&lt;00:00, 17.6kB/s]"
          }
        },
        "5b4b75c1564f4e41abcab49a091a626e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354c569156db4483be266ea8dcbae80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7ef785b2d8499b91617256246a217d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1af78e7bbe9742448a5a0c3a9b0f9e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3263615ad81a4213b7e098ea00239c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee447935831248b0acefa2f664834eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a7f2ebb16449ed8d8cd6f2830f5ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88af87d4c3d14fa8b9ac394b97bf1de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aef96889eaa440a0a87ababc00b59ad7",
              "IPY_MODEL_8671cf8ad187477ea54695a61a990cbc",
              "IPY_MODEL_1f6e0fc7a21e48118f08bddbfd18f3b3"
            ],
            "layout": "IPY_MODEL_3a6c5c8fefa74bf09c02aba988732b03"
          }
        },
        "aef96889eaa440a0a87ababc00b59ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10eaf4716a944ccf9350f6dba15ad90c",
            "placeholder": "​",
            "style": "IPY_MODEL_5b0c56220e7947438403a121f65218fb",
            "value": "Downloading: 100%"
          }
        },
        "8671cf8ad187477ea54695a61a990cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f991895fd1c49189c109aa864d1d8be",
            "max": 6431878936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8595b9e754e5422ea4d1e2e17b07a815",
            "value": 6431878936
          }
        },
        "1f6e0fc7a21e48118f08bddbfd18f3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03475638209e4281b8eb84df9479d407",
            "placeholder": "​",
            "style": "IPY_MODEL_97f36876520b43d69501acb85a1a7e73",
            "value": " 5.99G/5.99G [02:05&lt;00:00, 58.8MB/s]"
          }
        },
        "3a6c5c8fefa74bf09c02aba988732b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10eaf4716a944ccf9350f6dba15ad90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0c56220e7947438403a121f65218fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f991895fd1c49189c109aa864d1d8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8595b9e754e5422ea4d1e2e17b07a815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03475638209e4281b8eb84df9479d407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f36876520b43d69501acb85a1a7e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84f283d358a94b86a8f66c09a6c398ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36d3823db94140589de85aa7143c63b6",
              "IPY_MODEL_f42c6c2b23954afa8d0bbd29795369b2",
              "IPY_MODEL_de22e2c581074bf1a09bf56ac94ebd8c"
            ],
            "layout": "IPY_MODEL_eb38cdb3c6744b6b813e0460d60aa8ca"
          }
        },
        "36d3823db94140589de85aa7143c63b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f0713c8f664c32b892fa593278886b",
            "placeholder": "​",
            "style": "IPY_MODEL_abb5955232c6490f9cf3683bab8358ab",
            "value": "Downloading: 100%"
          }
        },
        "f42c6c2b23954afa8d0bbd29795369b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822b02f299284cf98bc01a27d162966b",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62d1c05c741f4dcd92b75cac018112bb",
            "value": 1042301
          }
        },
        "de22e2c581074bf1a09bf56ac94ebd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81412daefbe442d0ae842d03b520a120",
            "placeholder": "​",
            "style": "IPY_MODEL_74cec0ff0d7e4b82817122c76f332295",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 2.18MB/s]"
          }
        },
        "eb38cdb3c6744b6b813e0460d60aa8ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f0713c8f664c32b892fa593278886b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb5955232c6490f9cf3683bab8358ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "822b02f299284cf98bc01a27d162966b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d1c05c741f4dcd92b75cac018112bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81412daefbe442d0ae842d03b520a120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74cec0ff0d7e4b82817122c76f332295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ced663a772449d98ce83b2b2a0bd1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39b36f9eae1f4d75a09b2c5978716962",
              "IPY_MODEL_d976a416e4644043a8e69cfb1365d3b2",
              "IPY_MODEL_b060d292ce6b425d9508ef08ec83ddf4"
            ],
            "layout": "IPY_MODEL_d59de6dd4cc546c9945b64cdfb3984ba"
          }
        },
        "39b36f9eae1f4d75a09b2c5978716962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6a6c64388b425b85119fe024571117",
            "placeholder": "​",
            "style": "IPY_MODEL_172e7516c890431f8576b0b220f089c9",
            "value": "Downloading: 100%"
          }
        },
        "d976a416e4644043a8e69cfb1365d3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2a0a754276b4ea4a9930cbf33a92554",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_301046644cd74c1fb68bf189720cc302",
            "value": 456318
          }
        },
        "b060d292ce6b425d9508ef08ec83ddf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca62323240ef4d618b8f90354b335ffd",
            "placeholder": "​",
            "style": "IPY_MODEL_9c2ed608657c438c8effe3593facc7c2",
            "value": " 446k/446k [00:00&lt;00:00, 611kB/s]"
          }
        },
        "d59de6dd4cc546c9945b64cdfb3984ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6a6c64388b425b85119fe024571117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172e7516c890431f8576b0b220f089c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2a0a754276b4ea4a9930cbf33a92554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301046644cd74c1fb68bf189720cc302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca62323240ef4d618b8f90354b335ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c2ed608657c438c8effe3593facc7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c2e0f313e3a475894b6e9a7f69c1234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_588a98fa37064f05b62e0169b85c4fe3",
              "IPY_MODEL_64eab47ccb964ee5a34fa15fea0f3884",
              "IPY_MODEL_3f090c1347df4134ac5715c6f734cab8"
            ],
            "layout": "IPY_MODEL_f2005b719aaf45a285121887be243836"
          }
        },
        "588a98fa37064f05b62e0169b85c4fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57ab5f87007945ab899c36b72880a4d5",
            "placeholder": "​",
            "style": "IPY_MODEL_d24f73e424014b70a1caeae305937715",
            "value": "Downloading: 100%"
          }
        },
        "64eab47ccb964ee5a34fa15fea0f3884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2dc91b9cbb4a73947bad4370ef9f0d",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6cff96204c941cf8c306528169d405d",
            "value": 1355256
          }
        },
        "3f090c1347df4134ac5715c6f734cab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39712306a32846fc8e86389799892de6",
            "placeholder": "​",
            "style": "IPY_MODEL_1f931ff4e80946419c439f2cc4ffcc29",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 2.23MB/s]"
          }
        },
        "f2005b719aaf45a285121887be243836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ab5f87007945ab899c36b72880a4d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24f73e424014b70a1caeae305937715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b2dc91b9cbb4a73947bad4370ef9f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6cff96204c941cf8c306528169d405d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39712306a32846fc8e86389799892de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f931ff4e80946419c439f2cc4ffcc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}